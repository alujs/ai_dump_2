RecursiveLanguageModels
AlexL.Zhang
TimKraska
OmarKhattab
Abstract
Westudyallowinglargelanguagemodels(LLMs)
toprocessarbitrarilylongpromptsthroughthe
lensofinference-timescaling.Wepropose
Re-
cursiveLanguageModels
RLM
s),ageneral
inferenceparadigmthattreatslongpromptsas
partofanexternal
environment
andallowsthe
LLMto
programmatically
examine,decompose,
and
recursivelycallitselfover
snippetsofthe
prompt.WendthatRLMscansuccessfully
processinputsuptotwoordersofmagnitude
beyondmodelcontextwindowsand,evenfor
shorterprompts,dramaticallyoutperformthe
qualityofvanillafrontierLLMsandcommon
long-contextscaffoldsacrossfourdiverselong-
contexttaskswhilehavingcomparablecost.At
asmallscale,wepost-traintherstnatively
recursivelanguagemodel.Ourmodel,
RLM-
Qwen3-8B
,outperformstheunderlyingQwen3-
8Bmodelby
28
3%
onaverageandevenap-
proachesthequalityofvanillaGPT-5onthree
long-contexttasks.Codeisavailableat
https:
//github
com/alexzhang13/rlm
1.Introduction
Frontierreasoningmodelshavelimitedcontextwindows
and,evenwithintheirlimits,tendtoexhibit
context
rot
Hongetal.
2025
),aphenomenonillustratedinFig-
ure
wherequalitydegradessteeplyaspromptsgetlonger.
Thoughweexpectcontextlengthstosteadilyrisethrough
improvementstotraining,architecture,andinfrastructure,
weareinterestedin
whetheritispossibletoscalethecontext
sizeofgeneral-purposeLLMsbyordersofmagnitude
.This
isincreasinglyurgentasLLMsbegintobewidelyadopted
forlong-horizontasks,inwhichtheymustroutinelyprocess
tensifnothundredsofmillionsoftokens.
Westudythisquestionthroughthelensofscalinginference-
timecompute.Weareinspiredbythewaythat
reasoning
models
havebecomethefundamentalinterfacetoLLMs,
MITCSAIL,Cambridge,MA,USA.Correspondenceto:Alex
L.Zhang,OmarKhattab<altzhang@mit.edu,okhattab@mit.edu>.
Preprint.January29,2026.
Figure1.
AcomparisonofGPT-5andacorrespondingRLMusing
GPT-5onthreelong-contexttasksofincreasingcomplexity:
S-
NIAH
OOLONG
,and
OOLONG-Pairs
.Foreachtask,wescale
theinputlengthfrom
13
to
18
.GPT-5performancedegrades
signicantlyasafunctionofbothinputlengthandtaskcomplexity,
whiletheRLMmaintainsstrongperformance.Inputsbeyondthe
redregiondonottinGPT-5'scontextwindowof272Ktokens,
buttheRLMhandlesthemeffectively.Additionalexperiments
acrossothermodelsandbenchmarksarein
resultingnotonlyinempiricalgainsbutalsoadditionalthe-
oreticalexpressivepower(
Merrill&Sabharwal
2024
)com-
paredtovanillaTransformers.Thoughmostinference-time
methodsfordealingwithlongcontextaretask-specic(
Wu
etal.
2021
Changetal.
),themostpopulargeneral
approachis
contextcondensation
or
compaction
Khattab
Smith
OpenAI
2025b
Wuetal.
),
wherecontextfromuserrequestsoragenttrajectoriesis
repeatedlysummarizedonceitexceedsalengththreshold.
Unfortunately,compactionisrarelyexpressiveenoughfor
tasksthatrequiredenseaccessthroughouttheprompt.It
presumesthat
some
detailsthatappearearlyintheprompt
cansafelybeforgottentomakeroomfornewcontent.
Weintroduce
s),a
general-purposeinferenceparadigmfordramaticallyscaling
theeffectiveinputandoutputlengthsofLLMs.Thekey
8k
16k
33k
66k
131k
262k
524k
1M
20
40
60
80
100
Score (%)
GPT-5
S-NIAH
Input Context Length (log scale)
RLM(GPT-5)
Figure2.
ARecursiveLanguageModel(RLM)treatspromptsaspartoftheenvironment.Itloadstheinputpromptasavariableinsidea
REPLenvironment
andwritescodetopeekinto,decompose,andinvokeitselfrecursivelyoverprogrammaticsnippetsofthevariable.
insightisthatarbitrarilylonguserpromptsshouldnotbe
fedintotheneuralnetwork(e.g.,Transformer)directlybut
shouldinsteadbetreatedas
partoftheenvironmentthatthe
LLMistaskedto
symbolicallyandrecursively
interactwith
AsFigure
shows,anRLMexposesthesameexternal
interfaceasanLLMorareasoningmodel:itacceptsastring
promptofarbitrarystructureandproducesastringresponse.
Givenaprompt
,theRLMinitializesaRead-Eval-Print
Loop(REPL)programmingenvironmentinwhich
isset
asthevalueofavariable.ItthenofferstheLLMgeneral
contextabouttheREPLenvironment(e.g.,thelengthofthe
string
),andpermitsittowritecodethatpeeksintoand
decomposes
,andtoiterativelyobserveanysideeffects
fromexecution.Crucially,RLMsencouragetheLLMto
understand,transform,andexecutetheinputpromptby
writingsymbolicprogramsthatinvoketheLLMitself
onas
manyslicesoftheinputasnecessary.
Bytreatingthepromptitselfasanexternalobjectanden-
ablingsymbolicrecursion,RLMstacklelimitationsofex-
pressivepowerinrecentworkoncodingagents,retrieval
agents,andsub-agentdelegation.Inparticular,priorcoding
agentsandretrievalagentstreatsomedesignatedexternal
datasource(e.g.,alesystemoracorpusofsearchdocu-
ments)asanenvironmentforfetchingsnippets.However,
they
canonlylluptheunderlyingLLM'scontextwindow
withsnippetsbeforebreakingdown
.Similarly,priorself-
delegationapproaches(
Anthropic
SentientAI
Schroederetal.
Sunetal.
)allowLLMsto
invokethemselvesassub-agents.However,they
arehand-
icappedbytheunderlyingLLM'slimitedoutputlengths
becausetheyaredesignedtoverbalizesub-callsautoregres-
sivelyratherthanproducingthemprogrammatically.
WeevaluateRLMsusingafrontierclosedmodel(GPT-
5;
Singhetal.
)andafrontieropenmodel(Qwen3-
Coder-480B-A35B;
QwenTeam
)acrossfourtasks
withvaryinglevelsofcomplexity:deepresearch(
Chen
),informationaggregation(
Bertschetal.
coderepositoryunderstanding(
Baietal.
),andasyn-
theticpairwisereasoningtaskwhereevenfrontiermodels
failcatastrophically.WecompareRLMsagainstdirectLLM
callsaswellascontextcompaction,retrievaltool-useagents,
andcode-generationagents.
WendthatRLMsdemonstrateextremelystrongperfor-
manceevenatthe10M+tokenscale,andsubstantiallyout-
performallotherapproachesatlong-contextprocessing,in
manycasesbydouble-digitpercentagegainswhilemain-
tainingcomparablecost.Inparticular,asdemonstrated
inFigure
,RLMsexhibitfarlessseveredegradationfor
longercontextsandmoresophisticatedtasks.
Finally,atasmallscale,wepost-traintherstnatively
recursivelanguagemodel,demonstratingthatRLMscanbe
improvedquicklywithlittleadditionaltraining.Whilea
smallopenmodel(Qwen3-8B;
Yangetal.
)strugglesto
solvelongcontexttaskseveninanRLMscaffold,oursimple
general-purposetrainingrecipeusesonly1,000samples
fromunrelateddomainstoimproveitsperformancebya
medianof
acrossthefourevaluationtasks.
2.RecursiveLanguageModels
Givenabaseneurallanguagemodel
withmaximum
contextsize
,aRecursiveLanguageModel(RLM)is
aninference-timescaffoldaround
thattreatstheuser
promptaspartoftheenvironmentwithoutgivingupthe
abilitytodenselyprocessitscontentthroughdifferentcalls
.Givenanarbitrary-lengthpromptstring
,an
RLMinteractswithapersistentexternalenvironment
returnsaresponsestring
(Figure
).Wewouldlike
effectively
unboundedinputtokens
unbounded
outputtokens
,andan
unboundedsemantichorizon
,e.g.the
abilitytodo
semanticwork.
Algorithm
describeshowanRLMachievesthis.Given
aprompt
,theRLMinitializesapersistentREPLpro-
grammingenvironmentwithavariablecontainingtheuser
promptasastringandafunctionforinvokingasub-RLM
withanewprompt.Then,itstartstheRLMloop.Intherst
iteration,thealgorithminvokesthe
root
neuralmodel
withonly(constant-size)metadataabouttheuserprompt,
likeitslength,ashortprex,andhowtoaccesspartsofit.
Therootisinstructedviaprompting(Appendix
)and/or
ne-tuning(Appendix
)tooperatelikeanRLM:thatis,
generatecodethathelpsitunderstandandtransformits
partsofitsprompt
,andtobuildupintermediatevalues
andthenalresponseintonewvariables,potentiallyby
invokingthesub-RLMwithinloops
.InSection
,wend
thatexistingLLMscanbepromptedtodothisandthat
trainingan8Bmodeltobenativelyrecursiveispromising.
EachiterationoftheRLMloopexecutescodeintheREPL,
updatesREPLstate(intermediatevariables),andcollects
in
stdout
anyprintedtext.Only(constant-size)metadata
about
,likeashortprexandlength,isappended
'shistoryforthenextiteration.
OncetheRLMsets
thevariable
Final
insidetheREPL,iterationstopsandthe
valuein
isreturnedastheresponse.
RLMsmakethreesimpledesignchoicesthataremissing
fromexistingscaffolds.Tohighlightthese,weinclude
toillustrateadeceptivelysimilaralgorithm
thatisfarlessexpressive.Bothalgorithmssupportsome
notionofsub-calls,externalobjects,andcodeexecution,but
theydifferintermsofwherethepromptandintermediate
valuesliveandwhererecursionoccurs.
First,anRLMmustgivetheunderlyingLLM
symbolic
handle
totheuserprompt
,sothemodelcanmanipulateit
Thisiskey:itforces
torelyonvariablesandsub-callsto
managelongstringsinsteadofpollutingitswindow.Inprinciple,
ifwetrimeachturnto
tokens,wewillhaveatmost
K=c
iterations,eachofwhichcanlauncharbitrarilymanysub-calls.
Thisisnotafundamentallimitation,e.g.onecouldmovetheroot
horizonitselfintoavariable,butwetypicallywanttolimitthe
iterationsatanylevelofrecursionirrespective.
Algorithm1
Arecursivelanguagemodel,aroundLLM
Input:
prompt
Output:
response
state
InitREPL(prompt=P)
AddFunction(state
sub_RLM
hist
Metadata(state)
while
True
do
code
LLM
(hist)
REPL(state,code)
Metadata(stdout)
if
state[Final]
then
return
Algorithm2
Alternatescaffoldwithstandard(poor)design
choicesforprompts,sub-calls,andcodeexecution
actions
Finish
Exec
Search
sub_LLM
Metadata(actions)
;P
//
Flaw#1
action
val
is
Flaw#2
out
RUN(action,val)
Flaw#3
Tok(hist)
>K
Compact(hist)
withoutcopyingtextintotherootcontextwindow.Instead,
ineffectiveAlgorithm
startsbyputtingtheuserprompt
intotheLLMcontextwindow(
)andthusinherits
thewindowlimitationsof
andfallsbacktoheuristics
likecontextcompaction.Eventhoughthescaffoldcanac-
cessexternaldatawith,say,a
actionorlesystem
access,itisfatallyboundedwithrespecttouserinput.
Second,ineffectiveAlgorithm
asks
toautoregressively
generatetheoutputdirectly,viaa
action.Thismay
seeminnocuous,butitmeansthatitalsocannotgenerate
longeroutputsthanthecontextwindowof
permits.
Third,andperhapsmostimportantly,anRLMrequires
sym-
bolicrecursion
.Thatis,coderunning
inside
mustbe
abletoinvoke
onprogrammaticallyconstructedtrans-
formationsof
(e.g.,insidearbitrarilylargeloops),storing
intermediateresultssymbolically.ThoughAlgorithm
in-
cludesbothacodeexecutionactionandasub-LLMaction
separately,itisnotabletoinvokethesub-LLMprogrammat-
icallyandhencecanonlydelegateafew
explicitlyverbalized
tasks
ratherthanwritingshortprogramsthatcan,say,loop
overslicesofthepromptandlaunch
oreven
processestounderstandortransformallpartsof
3.ScalingLongContextTasks
Wehypothesizethattheeffectivecontextwindow(
Hsieh
Goldmanetal.
)ofan
LLMcannotbeunderstoodindependentlyofthe
specic
task
.Thatis,morecomplexproblemswillexhibitdegra-
dationateven
shorter
lengthsthansimplerones.Because
ofthis,wemustcharacterizetasksintermsofhowtheir
complexity
scaleswithpromptlength
Forexample,needle-in-a-haystack(NIAH)problemsgener-
allykeep`needles'constantaspromptlengthisscaled.Asa
result,frontiermodelscannowreliablysolvethesetasksin
RULER(
Hsiehetal.
)inthe1M+tokensettingsbut
struggleatfarshorterlengthsonOOLONG(
),ataskwheretheanswerdependsexplicitlyonalmost
everylineintheprompt.
3.1.Tasks
Wedesignourevaluationaroundtaskswherewecanvary
thelengthsoftheprompts,sowecanconsiderproblems
whosedifcultiesscaledifferentlywithcontextlength.
.Followingthesingleneedle-in-the-haystacktask
inRULER(
),weconsiderasetof50
singletasksthatrequirendingaspecicphraseornumber
inalargesetofunrelatedtext.Here,theinformationbeing
soughtscalesas
(1)
withrespecttoinputlength.
BrowseComp-Plus(1Kdocuments)
Chenetal.
).
Amulti-hopquestion-answeringbenchmarkforDeepRe-
search(
2025a
)questionsthatrequiresreasoning
overmultipledifferentdocuments.Thebenchmarkprovides
averiedofinecorpusthatisguaranteedtocontaingold,
evidence,andhardnegativedocumentsforeachquestion.
Following
),weuse150randomlysampled
instancesasourevaluationset;weprovide
1000
randomly
chosendocumentsasinput,inwhichthegoldandevidence
documentsareguaranteedtoexist.Wereportthepercentage
ofcorrectanswers.Theanswertoeachtaskrequirespiec-
ingtogetherinformationfromseveraldocuments,making
thisharderthan
despitealsorequiringaconstant
numberofdocuments.
).Alongreasoningbench-
markthatrequirestransformingchunksoftheinputseman-
tically,thenaggregatingthesechunkstoformanalan-
swer.Wereportscoringbasedontheoriginalpaper,which
scoresnumericalanswersas
score
(^
)=0
75
otheranswersasexactmatch.Wefocusspecicallyonthe
trec_coarse
split,asetof
50
tasksoveradatasetof
ThishelpsexplainthepatternsseeninFigure
earlier:
scaleseffectivelyontheS-NIAHtask,wheretheneedlesizeis
constantdespitelongerprompts,butshowsfasterdegradation
atincreasingly
contextlengthsonthe
linear
-complexity
OOLONGandthe
quadratic
-complexityOOLONG-Pairs.
questionswithsemanticlabels.Eachtaskrequiresusing
nearlyallentriesofthedataset,andthereforescaleslinearly
inprocessingcomplexityrelativetotheinputlength.
.Wemodifythe
splitof
OOLONGtoinclude
newqueriesthatspecicallyrequire
aggregating
pairs
ofchunkstoconstructthenalanswer.
WereportF1scoresovertheanswer.Eachtaskrequires
usingnearlyall
ofentriesofthedataset,andtherefore
requiresprocessingquadratically-manyitemsrelativetothe
inputlength.InAppendix
D.1
,weprovideallqueriesin
thisbenchmark.
LongBench-v2CodeQA
).Amulti-choice
coderepositoryunderstandingsplitfromLongBench-v2that
ischallengingformodernfrontiermodels.Wereportthe
scoreasthepercentageofcorrectanswers.Eachinstance
requiresreasoningoveraxednumberoflesinacodebase
tondtherightanswer.
3.2.MethodsandBaselines
WecompareRLMsagainstcommonlyusedtask-agnostic
inferencemethods,usingtwomodernLMs,GPT-5with
mediumreasoning(
)anddefaultsampling
parameters,andQwen3-Coder-480B-A35B(
)usingthesamplingparametersdescribedin
Qwen
Team
).ForQwen3-Coder-480B-A35B,wecompute
costsbasedonthecomputeproviderFireworks(
Fireworks
AI
).Inadditiontoevaluatingthebasemodelonall
tasks,wealsoevaluatethefollowingmethodsandbaselines:
CodeAct(+BM25).
WecomparedirectlytoaCode-
Act(
Wangetal.
)agentthatcanexecutecodeinsideof
aReAct(
Yaoetal.
2023
)loop.UnlikeanRLM,CodeAct
doesnotofoadtheuserprompttothecodeenvironment,
andinsteadprovidesitdirectlytotheLM.Furthermore,fol-
lowing
Jimenezetal.
);
),weequip
thisagentwithaBM25(
Robertson&Zaragoza
2009
)re-
trieverthatindexestheinputcontextfortaskswhereare-
trieverisappropriate.
CodeActwithsub-calls.
Tospecicallyablateofoading
thecontextasavariableintheREPL,weevaluateaCode-
)baselinewiththeabilitytoinvoke
sub-LMcalls.ComparedtoRLMs,thismethodloadsthe
contextdirectlyintothemodel.
Summaryagent.
Yuetal.
),weconsideraniterativeagentthat
compactsthecontextasitislled.Forexample,givena
corpusofdocuments,itwilliterativelyaccumulatethedoc-
umentsandsummarizewhenfull.Incaseswhereasingle
documentexceedsthemodelwindow,theagentwillchunkit
totwithinthemodelcontextwindowandinvokethesame
strategyoverthesechunks.FortheGPT-5experiments,
duetotheextremelyhighcostofapplyingthisstrategyto
Table1.
Performancecomparisonofdifferentmethodsacrosslong-contextbenchmarksofvaryingcomplexity.In
gray
istheaverageAPI
cost
thestandarddeviationofeachmethodoneachtask.
indicatesrunswhereamethod(sometimes)ranintoinputcontextlimits.
ProvidercostswerecomputedunderOpenAIforGPT-5andFireworksforothermodels.Non-zeroscoresareroundedtoatleast
ModelCodeQABrowseComp+(1K)OOLONGOOLONG-Pairs
TaskLength
(tokens)
23K-4.2M6M-11M131K32K
(withRLMsub-callstoGPT-5-mini)
BaseModel24.0
($0.13
$0.07)
0.0
(N/A)
44.0
($0.14
$0.02)
0.1
($0.16
$0.10)
CodeAct(+BM25)22.0
($0.06
$0.08)
51.0
($0.71
$1.20)
38.0
($0.61
$1.06)
24.7
($0.75
$0.43)
CodeAct(+sub-calls)24.0
40.0
($0.85
$1.27)
28.4
($1.11
$0.62)
Summaryagent58.0
($1.31
$1.46)
70.5
($0.57
46.0
$0.01)
$0.09)
62.0
($0.11
91.3
($0.99
$1.22)
56.5
($0.43
$0.85)
58.0
($0.33
$0.20)
RLM(nosub-calls)58.0
($0.18
$0.56)
88.0
($0.44
$0.90)
36.0
($0.37
$0.42)
43.9
($0.69
$1.16)
Qwen3-Coder-480B-A35B
BaseModel20.0
$0.00)
($0.05
CodeAct(+BM25)24.0
($0.17
12.7
($0.39
$0.50)
($1.51
$1.09)
0.3
($1.54
$0.35)
CodeAct(+sub-calls)26.0
($0.28
$0.30)
32.0
($1.83
$1.14)
($1.49
$0.46)
Summaryagent50.0
($1.26
$1.50)
($8.98
$2.12)
44.1
($0.15
0.31
RLM56.0
($0.92
$1.23)
44.7
($0.84
$0.63)
48.0
$0.49)
23.1
($1.02
$0.52)
RLM(nosub-calls)
66.0
$0.58)
($0.82
$0.69)
43.5
($0.32
$0.13)
17.3
($1.77
BaseModel4.0
($0.01
RLM26.0
($0.04
2.0
($0.03
$0.06)
24.0
($0.19
$0.26)
4.3
$0.05)
RLM(ne-tuned)
($0.02
14.0
$0.03)
5.2
millionsoftokens,weuseGPT-5-nanoforcompactionand
GPT-5toprovidethenalanswer.
RLMwithREPL
.WeimplementanRLMwithaPython
REPLenvironment,whichloadsamoduleforqueryinga
sub-LMandusesasystempromptpresentedinAppendix
FortheGPT-5experiments,weuseGPT-5-miniforthe
recursiveLMsandGPT-5fortherootLM,aswefoundthis
choicetostrikeagoodbalancebetweenthecapabilitiesof
RLMsandthecostoftherecursivecalls.WenotateaRLM
usingamodelasRLM(model),e.g.RLM(GPT-5).
RLMwithREPL,nosub-calls
.Weprovideanablation
ofourmethod,inwhichthepromptisloadedinaREPL
environmentwithouttheabilitytoinvokesub-LMcalls.
Finetuning.
Tocreate
RLM-Qwen3-8B
,wenetune
Qwen3-8Bon1,000lteredtrajectoriesofQwen3-Coder-
480B-A35BasanRLMwithQwen3-8Bsub-callsonLong-
BenchPro(
2026
)tasks.Weusesamplingpa-
rametersdescribedin
),andevaluatethe
ne-tunedRLM-Qwen3-8BasanRLMonourlongcontext
tasks.Thekeyinsightfortrainingisthatbeinganeffective
sub-callmodelisroughlysimilartobeingageneralpurpose
reasoningmodel,sowecanmakethetrainingmuchmore
tractable(andseeminglyshort-horizon)atsmallscalebyfo-
cusingonimprovingtherootmodel'sabilitytomanipulate
theREPLandtolaunchrecursivecalls.Weprovidemore
trainingdetailsinAppendix
4.ResultsandDiscussion
Table
reportsourmainresults.Weadditionallyexplore
howvanillafrontiermodelperformanceandRLMperfor-
mancedegradesasinputcontextsgrowinFigure
Observation1:RLMscanscaletothe10M+token
regimeandcanoutperformbaseLMsandexistingtask-
agnosticagentscaffoldsonlongcontexttasks
.Acrossall
tasks,RLMsdemonstratestrongperformanceonprompts
wellbeyondtheeffectivecontextwindowofafrontierLM,
outperformingbasemodelsandcommonlong-contextscaf-
foldsbyupto
theperformancewhilemaintainingcom-
parableorcheaperaveragetokencosts.Notably,RLMs
scalewellbeyondthebasemodels'contextwindow.For
Figure3.
CostofRLMandbaselinesdescribedin
3.2
plottedatthe25th,50th,75th,and95thpercentileoftotalAPIcost.Weobserve
comparableorevenlowercostsforRLMsatthe50thpercentile,butsharpincreasesatthetailendduetopotentiallylongRLMtrajectories.
instance,onBrowseComp-Plus(1K),alinearlyextrapo-
latedcostforGPT-5-miniingesting6-11Minputtokensis
$1
$2
,whileRLM(GPT-5)hasanaveragecostof
$0
99
andoutperformsboththesummarizationandretrieval
baselinesbyover
29%
Furthermore,ontaskswhereprocessingcostsscalewiththe
inputcontext,RLMsmakesignicantimprovementsover
thebasemodel,evenontaskswithinthemodel'scontext
window.OnOOLONG,theRLMwithGPT-5andQwen3-
Coderoutperformthebasemodelby
4%
33
respectively.OnOOLONG-Pairs,bothGPT-5andQwen3-
CodermakelittleprogresswithF1scoresof
1%
,while
theRLMusingthesemodelsachieveF1scoresof
58
0%
23
respectively,highlightingtheemergentcapabilityof
RLMstohandleextremelyinformation-densetasks.
Observation2:TheREPLisnecessaryforhandling
longinputs,whiletherecursivesub-callingofRLMs
providesstrongbenetsoninformation-denseinputs.
keycharacteristicofRLMsisofoadingthecontextasa
variableinanenvironment
thatthemodelcaninteract
with.Evenwithoutsub-callingcapabilities,ourablationof
theRLMisabletoscalebeyondthecontextlimitofthe
modelandoutperformothertask-agnosticbaselinesonmost
longcontextsettings.OntheCodeQAandBrowseComp+
taskswithQwen3-Coder,thisablationisabletooutperform
theRLMby
17
9%
respectively.
Oninformation-densetaskslikeOOLONGorOOLONG-
Pairs,weobservedseveralcaseswhererecursiveLMsub-
callingisnecessary.In
4.1
,weseeRLM(Qwen3-Coder)
performthenecessarysemantictransformationline-by-line
throughrecursivesub-calls,whiletheablationwithoutsub-
callsisforcedtousekeywordheuristicstosolvethesetasks.
Acrossallinformation-densetasks,RLMsoutperformthe
ablationwithoutsub-callingby
10%
59%
Observation3:LMperformancedegradesasafunction
ofinputlengthandproblemcomplexity,whileRLM
performancescalesbetter.
ThebenchmarksS-NIAH,OO-
LONG,andOOLONG-Pairscontainaxednumberoftasks
overcontextswithlengthsrangingfrom
.Each
benchmarkcanbelooselycategorizedbydifferentprocess-
ingcomplexityoftheinputcontextwithrespecttolength
(roughlyconstant,linear,andquadraticrespectively).In
Figure
,wedirectlycompareanRLMusingGPT-5tobase
GPT-5oneachtask.WendthatGPT-5performancede-
gradessignicantlyfasterformorecomplextasks,while
RLMperformancedegradesatamuchslowerrate,which
alignswiththendingsof
).Forcon-
textlengthsbeyond
14
,theRLMconsistentlyoutperforms
GPT-5.
Furthermore,RLMcostsscaleproportionallytothecom-
plexityofthetask,whilestillremaininginthesameorderof
magnitudeofcostasGPT-5(seeFigure
11
inAppendix
In
,weexplorethechoicesthattheRLMmakesthat
causethesedifferencesincost.Lastly,inthissetting,we
alsoobservethatthebaseLMoutperformsRLMinthe
smallinputcontextregime.Byconstruction,aRLMhas
strictlymorerepresentationcapacitythananLM.Inprac-
tice,however,weobservethatRLMperformanceisslightly
worseonsmallerinputlengths,suggestingatradeoffpoint
betweenwhentouseabaseLMandwhentouseanRLM.
Observation4:TheinferencecostofRLMsremains
comparabletoabaseLMcallbuthashighvariance
duetodifferencesintrajectorylengths.
RLMsiteratively
interactwiththeircontextuntiltheyndasuitableanswer,
leadingtolargedifferencesiniterationlengthdependingon
taskcomplexity.InFigure
,weplotthequartilecostsfor
eachmethodacrossallexperimentsinTable
excluding
BrowseComp-Plus(1K),asthebasemodelscannottany
ofthesetasksincontext.ForGPT-5,themedianRLMrun
ischeaperthanthemedianbasemodelrun,butmanyoutlier
RLMrunsaresignicantlymoreexpensivethananybase
modelquery.However,comparedtothesummarization
agentwhichingeststheentireinputcontext,RLMsareupto
cheaperwhilemaintainingstrongerperformanceacross
alltasksbecausetheRLMisabletoselectivelyviewcontext.
Weadditionallyreportruntimenumbersofeachmethodin
Figures
,butwenoteseveralimportant
caveats.UnlikeAPIcosts,thesenumbersareheavilydepen-
dentonimplementationdetailssuchasthemachineused,
APIrequestlatency,andtheasynchronyofLMcalls.Inour
implementationofthebaselinesandRLMs,allLMcalls
areblocking/sequential.Nevertheless,similartocosts,we
observeawiderangeofruntimes,especiallyforRLMs.
Observation5:RLMsareamodel-agnosticinference
strategy,butdifferentmodelsexhibitdifferentoverall
decisionsoncontextmanagementandsub-calling.
While
GPT-5andQwen3-Coder-480Bbothexhibitstrongperfor-
manceasRLMsrelativetotheirbasemodelandotherbase-
lines,theyalsoexhibitdifferentperformanceandbehavior
acrossalltasks.OnBrowseComp-Plus(1k)inparticular,
RLM(GPT-5)nearlysolvesalltaskswhileRLM(Qwen3-
Coder)strugglestosolvehalf.
WenotethattheRLMsystempromptisxedforeachmodel
acrossallexperimentsandisnottunedforanyparticular
benchmark.BetweenGPT-5andQwen3-Coder,theonly
differenceinthepromptisanextralineintheRLM(Qwen3-
Coder)promptwarningagainstusingtoomanysub-calls
(seeAppendix
).Weprovideanexplicitexampleofthis
differenceinexample
E.3
,whereRLM(Qwen3-Coder)
launchesasub-callperlineinOOLONGwhileGPT-5is
conservativeaboutsub-queryingLMs.
Observation6:TrainingRLMsononedomaincanim-
provegeneraldownstreamRLMperformance.
Certain
behaviorinRLMtrajectoriesarecommonamongdiffer-
entdomains,suchasprobingtheinputandrecursively
sub-callingonshortercontexts.InTable
,wendthat
,aQwen3-8Bmodelthatwene-tuned
onRLM(Qwen3-Coder-480B-A35B)trajectoriesonasmall,
unrelated
setoftasks(LongBenchPro;
considerablyoutperformsthebaseQwen3-8BasanRLM
by
onaverage.Furthermore,itsinferencecostsare
muchlowerduetobetterdecisionmakingandfewermis-
takesasanRLM.
4.1.EmergentPatternsinRLMTrajectories
Evenwithoutexplicittraining,RLMsexhibitinterestingcon-
textandproblemdecompositionbehavior.Weselectseveral
examplesofsnippetsfromRLMtrajectoriestounderstand
howtheysolvelongcontextproblemsandwheretheycan
improve.Wediscussparticularexamplesofinterestingbe-
haviorhere,withadditionalexamplesinAppendix
Chunkingandrecursivelysub-callingLMs.
RLMsdefer
essentiallyunbounded-lengthreasoningchainstosub-LM
calls.Thechoiceofdecompositioncangreatlyaffecttask
performance,especiallyforinformation-denseproblems.
Inourexperiments,wedidnotobservecomplicatedpar-
titioningstrategiesbeyonduniformchunkingorkeyword
searches.InFigure
b,RLM(Qwen3-Coder)chunksby
newlineina1000+linecontextfromOOLONG.
Filteringinputinformationusingcodeexecutionbased
onmodelpriors.
AkeyintuitionforwhytheRLMab-
stractioncanmaintainstrongperformanceonhugeinputs
withoutexplodingcostsistheLM'sabilitytolterinput
contextwithoutexplicitlyseeingit.Furthermore,model
priorsenabletheRLMtonarrowthesearchspaceandpro-
cessfewerinputtokens.Asanexample,inFigure
a,we
observedRLM(GPT-5)using
regex
queriestosearchfor
chunkscontainingkeywordsintheoriginalprompt(e.g.
festival)andphrasesithasapriorabout(e.g.LaUnion).
PassingrecursiveLMoutputsthroughvariablesforlong
outputtasks.
RLMsareabletoproduceessentiallyun-
boundedtokenswellbeyondthelimitofthebaseLMby
returningvariablesintheREPLasoutput.Throughthe
REPL,theRLMcaniterativelyconstructthesevariables
asamixtureofprogrammaticandsub-(R)LMoutputcalls.
WeobservedthisstrategyusedheavilyinOOLONG-Pairs
trajectories,wheretheRLMstoredtheoutputofsub-LM
callsovertheinputinvariablesandstitchedthemtogether
toformanalanswer(seeFigure
c).
5.RelatedWorks
Long-ContextLMSystems.
Therehaveprimarilybeen
twoorthogonaldirectionsforlong-contextmanagement
inlanguagemodelsystems:1)directlychangingthear-
chitectureofandretrainingthebaseLMtohandlelonger
contexts(
Pressetal.
2022
Guetal.
Munkhdalai
),and2)buildingascaffoldaroundtheLM
thatimplicitlyhandlesthecontextRLMsfocusonthe
latter.Onepopularclassofsuchstrategiesis
lossy
management,whichusessummarizationortruncationto
compresstheinputcontextatthecostofpotentiallylosing
ne-grainedinformation.Forexample,MemWalker(
)constructsatree-likedatastructureofthein-
putthattheLMcannavigatewhenansweringlongcontext
questions.ReSum(
)isanotherworkthat
addsasummarizationtooltoperiodicallycompressthe
contextofamulti-turnagent.Anotherclassofstrategies
implementanexplicitmemoryhierarchyintheagentscaf-
fold(
Packeretal.
Chhikaraetal.
Zhangetal.
).RLMsdifferfromtheseworksinthatallcontext
windowmanagementisimplicitlyhandledbytheLMitself.
TaskDecompositionthroughsub-LMcalls.
ManyLM-
basedagents(
Guoetal.
)usemul-
tiple,well-placedLMcallstosolveaproblem;however,
manyofthesecallsareplacedbasedonhuman-engineered
workows.SeveralmethodslikeViperGPT(
Sursetal.
),THREAD(
),DisCIPL(
Grand
),ReDel(
Zhuetal.
),ContextFolding(
Sun
),andAgentFold(
Yeetal.
)haveexplored
deferringthechoiceofsub-LMcallstotheLM.Thesetech-
niquesemphasize
decompositionthroughrecursiveLM
calls,butareunabletohandlelongcontextinputsbeyond
Figure4.
RLMshavecommonpatternsintheirtrajectorieswhensolvingtasks.(a)WefrequentlyobservedRLMslteringandinteracting
withtheircontextthrough
code.(b)WefoundthatRLMscaneffectivelydecomposetheircontextthroughrecursivesub-calls(c)
Onlong-outputtasks,RLMsareabletosolvesub-problemsusingrecursivesub-LMcallsandstitchtheiroutputstoformanaloutput.
thelengthofthebaseLM.RLMs,ontheotherhand,are
enabledbyanextremelysimpleintuition(i.e.,placingthe
promptintheexternalenvironment)to
symbolically
manip-
ulatearbitrarilylongstringsandtoiterativelyrenetheir
recursionviaexecutionfeedbackfromthepersistentREPL.
6.LimitationsandFutureWork
WhileRLMsshowstrongperformanceontasksbeyondthe
contextwindowlimitationsofexistingLMsatreasonable
inferencecosts,evaluationsformoredifcultandnatural
long-contextprocessingtasksandthebestmechanismsfor
implementingRLMsbothremainhighlyunder-explored.
Wefocusedonsynchronoussub-callsinsideofaPython
REPLenvironment,butwenotethatalternativestrategiesin-
volvingasynchronoussub-callsandsandboxedREPLscan
potentiallysignicantlyreducetheruntimeandinference
costofRLMs.Furthermore,wechosetouseamaxrecur-
siondepthofone(i.e.sub-callsareLMs);whilewefound
strongperformanceonexistinglong-contextbenchmarks,
webelievethatfutureworkshouldinvestigatedeeperlevels
ofrecursionorevennewhybridsbetweensymbolicrecur-
sionandneuralattention.Weincludeadditionallimitations
andnegativeresultsinAppendix
Lastly,wefocusedourexperimentsonevaluatingRLMs
using
existing
frontiermodels,butshowinitialevidenceona
Qwen3-8Bmodelthatexplicitlytrainingamodeltobeused
asaRLMprovidesveryrapidperformanceimprovements,
evenoutsidethetrainingdomain.WehypothesizethatRLM
trajectoriescanbeviewedasaformofreasoning(
DeepSeek-AIetal.
),whichcanbetrained
bybootstrappingexistingmodels(
Zelikmanetal.
).WehopethattrainingnativeRLMscanbetreatedas
anewaxisofscaletoimproveLMperformanceongeneral
andlong-horizontasks.
7.Conclusion
WeintroducedRecursiveLanguageModels(RLMs),agen-
eralinferenceframeworkforlanguagemodelsthatofoads
theinputcontextandenableslanguagemodelstorecur-
sivelysub-querylanguagemodelsbeforeprovidinganout-
put.Weexploredaninstantiationofthisframeworkthat
ofoadsthecontextintoaPythonREPLenvironmentas
avariableinmemory,enablingtheLMtoreasonoverits
contextincodeandrecursiveLMcalls,ratherthanpurelyin
tokenspace.Ourresultsacrossmultiplesettingsandmod-
elsdemonstratedthatRLMsareaneffectivetask-agnostic
paradigmforbothlong-contextproblemsandgeneralrea-
soning.Buildingonoursmallne-tuningexperiments,we
areexcitedtoseefutureworkthatexplicitlytrainsmodels
toreasonasRLMs,whichcouldresultinanotheraxisof
scaleforthenextgenerationoflanguagemodelsystems.
8.ImpactStatement
Thispaperexploresastrategyforenablinglanguagemodels
tosolvelongcontextproblemsandscalingfuturelanguage
modelsystems.Thegoalistoadvanceresearchonsystems
thatcanhelpussolvecomplexproblems.Whilethereare
potentialsocietalconsequencesofthiswork,webelieve
theyarenotspecictothispaperanddonotneedtobe
highlightedhere.
Acknowledgments
ThisresearchispartiallysupportedbytheLaudeInstitute,
PrimeIntellect,andModalLabs.WethankNoahZiems,
JacobLi,JamesMoore,andtheMITOASYSandMITDSG
labsforinsightfuldiscussionsthroughoutthisproject.We
alsothankJackCook,MatejSirovatka,OrPress,Sebastian
Mller,SimonGuo,andZedLiforhelpfulfeedback.
References
Anthropic.Claudecode:Subagentsmodular
aiworkowswithisolatedagentcontexts,2025.
URL
https://docs
anthropic
com/en/docs/
claude-code/sub-agents
Bai,Y.,Tu,S.,Zhang,J.,Peng,H.,Wang,X.,Lv,X.,
Cao,S.,Xu,J.,Hou,L.,Dong,Y.,Tang,J.,andLi,
J.Longbenchv2:Towardsdeeperunderstandingand
reasoningonrealisticlong-contextmultitasks,2025.URL
https://arxiv
org/abs/2412
15204
Bertsch,A.,Pratapa,A.,Mitamura,T.,Neubig,G.,and
Gormley,M.R.Oolong:Evaluatinglongcontextrea-
soningandaggregationcapabilities,2025.URL
//arxiv
org/abs/2511
02817
Chang,Y.,Lo,K.,Goyal,T.,andIyyer,M.Booookscore:A
systematicexplorationofbook-lengthsummarizationin
theeraofLLMs.In
TheTwelfthInternationalConference
onLearningRepresentations
,2024.URL
https://
arxiv
org/pdf/2310
00785
pdf
Chen,H.,Pasunuru,R.,Weston,J.,andCelikyilmaz,
A.Walkingdownthememorymaze:Beyondcontext
limitthroughinteractivereading,2023.URL
org/abs/2310
05029
Chen,Z.,Ma,X.,Zhuang,S.,Nie,P.,Zou,K.,Liu,
A.,Green,J.,Patel,K.,Meng,R.,Su,M.,Sharify-
moghaddam,S.,Li,Y.,Hong,H.,Shi,X.,Liu,X.,
Thakur,N.,Zhang,C.,Gao,L.,Chen,W.,andLin,J.
Browsecomp-plus:Amorefairandtransparentevalu-
ationbenchmarkofdeep-researchagent,2025.URL
org/abs/2508
06600
Chen,Z.,Wu,X.,Jia,J.,Gao,C.,Fu,Q.,Zhang,D.,andHu,
S.Longbenchpro:Amorerealisticandcomprehensive
bilinguallong-contextevaluationbenchmark,2026.URL
org/abs/2601
02872
Chhikara,P.,Khant,D.,Aryan,S.,Singh,T.,andYa-
dav,D.Mem0:Buildingproduction-readyaiagents
withscalablelong-termmemory,2025.URL
org/abs/2504
19413
DeepSeek-AI,Guo,D.,Yang,D.,Zhang,H.,Song,J.,
Zhang,R.,Xu,R.,Zhu,Q.,Ma,S.,Wang,P.,Bi,X.,
Zhang,X.,Yu,X.,Wu,Y.,Wu,Z.F.,Gou,Z.,Shao,
Z.,Li,Z.,Gao,Z.,Liu,A.,Xue,B.,Wang,B.,Wu,B.,
Feng,B.,Lu,C.,Zhao,C.,Deng,C.,Zhang,C.,Ruan,
C.,Dai,D.,Chen,D.,Ji,D.,Li,E.,Lin,F.,Dai,F.,Luo,
F.,Hao,G.,Chen,G.,Li,G.,Zhang,H.,Bao,H.,Xu,
H.,Wang,H.,Ding,H.,Xin,H.,Gao,H.,Qu,H.,Li,
H.,Guo,J.,Li,J.,Wang,J.,Chen,J.,Yuan,J.,Qiu,J.,
Li,J.,Cai,J.L.,Ni,J.,Liang,J.,Chen,J.,Dong,K.,
Hu,K.,Gao,K.,Guan,K.,Huang,K.,Yu,K.,Wang,L.,
Zhang,L.,Zhao,L.,Wang,L.,Zhang,L.,Xu,L.,Xia,
L.,Zhang,M.,Zhang,M.,Tang,M.,Li,M.,Wang,M.,
Li,M.,Tian,N.,Huang,P.,Zhang,P.,Wang,Q.,Chen,
Q.,Du,Q.,Ge,R.,Zhang,R.,Pan,R.,Wang,R.,Chen,
R.J.,Jin,R.L.,Chen,R.,Lu,S.,Zhou,S.,Chen,S.,Ye,
S.,Wang,S.,Yu,S.,Zhou,S.,Pan,S.,Li,S.S.,Zhou,
S.,Wu,S.,Ye,S.,Yun,T.,Pei,T.,Sun,T.,Wang,T.,
Zeng,W.,Zhao,W.,Liu,W.,Liang,W.,Gao,W.,Yu,W.,
Zhang,W.,Xiao,W.L.,An,W.,Liu,X.,Wang,X.,Chen,
X.,Nie,X.,Cheng,X.,Liu,X.,Xie,X.,Liu,X.,Yang,
X.,Li,X.,Su,X.,Lin,X.,Li,X.Q.,Jin,X.,Shen,X.,
Chen,X.,Sun,X.,Wang,X.,Song,X.,Zhou,X.,Wang,
X.,Shan,X.,Li,Y.K.,Wang,Y.Q.,Wei,Y.X.,Zhang,
Y.,Xu,Y.,Li,Y.,Zhao,Y.,Sun,Y.,Wang,Y.,Yu,Y.,
Zhang,Y.,Shi,Y.,Xiong,Y.,He,Y.,Piao,Y.,Wang,Y.,
Tan,Y.,Ma,Y.,Liu,Y.,Guo,Y.,Ou,Y.,Wang,Y.,Gong,
Y.,Zou,Y.,He,Y.,Xiong,Y.,Luo,Y.,You,Y.,Liu,Y.,
Zhou,Y.,Zhu,Y.X.,Xu,Y.,Huang,Y.,Li,Y.,Zheng,
Y.,Zhu,Y.,Ma,Y.,Tang,Y.,Zha,Y.,Yan,Y.,Ren,Z.Z.,
Ren,Z.,Sha,Z.,Fu,Z.,Xu,Z.,Xie,Z.,Zhang,Z.,Hao,
Z.,Ma,Z.,Yan,Z.,Wu,Z.,Gu,Z.,Zhu,Z.,Liu,Z.,Li,
Z.,Xie,Z.,Song,Z.,Pan,Z.,Huang,Z.,Xu,Z.,Zhang,
Z.,andZhang,Z.Deepseek-r1:Incentivizingreasoning
capabilityinllmsviareinforcementlearning,2025.URL
org/abs/2501
12948
FireworksAI.Qwen3coder480ba35binstruct.
https://fireworks
ai/models/fireworks/
qwen3-coder-480b-a35b-instruct
,2025.
Goldman,O.,Jacovi,A.,Slobodkin,A.,Maimon,A.,Da-
gan,I.,andTsarfaty,R.Isitreallylongcontextifall
youneedisretrieval?towardsgenuinelydifcultlong
contextnlp,2025.URL
org/abs/
2407
00402
Grand,G.,Tenenbaum,J.B.,Mansinghka,V.K.,Lew,
A.K.,andAndreas,J.Self-steeringlanguagemodels.
arXivpreprintarXiv:2504.07081
Gu,A.,Goel,K.,andR,C.Efcientlymodelinglong
sequenceswithstructuredstatespaces,2022.URL
org/abs/2111
00396
Guo,T.,Chen,X.,Wang,Y.,Chang,R.,Pei,S.,Chawla,
N.V.,Wiest,O.,andZhang,X.Largelanguage
modelbasedmulti-agents:Asurveyofprogressand
challenges,2024.URL
2402
01680
Hong,K.,Troynikov,A.,andHuber,J.Context
rot:Howcontextdegradationaffectsllmperformance,
2025.URL
https://research
trychroma
com/
context-rot
Hsieh,C.-P.,Sun,S.,Kriman,S.,Acharya,S.,Rekesh,D.,
Jia,F.,Zhang,Y.,andGinsburg,B.Ruler:What'sthereal
contextsizeofyourlong-contextlanguagemodels?,2024.
org/abs/2404
06654
Intellect,P.Primerllibrary,2025.URL
github
com/PrimeIntellect-ai/prime-rl
Jimenez,C.E.,Yang,J.,Wettig,A.,Yao,S.,Pei,K.,Press,
O.,andNarasimhan,K.Swe-bench:Canlanguage
modelsresolvereal-worldgithubissues?,2024.URL
06770
Khattab,O.,Potts,C.,andZaharia,M.Baleen:Robust
multi-hopreasoningatscaleviacondensedretrieval.
Ad-
vancesinNeuralInformationProcessingSystems
,34:
2767027682,2021.
Merrill,W.andSabharwal,A.Theexpressivepowerof
transformerswithchainofthought.In
TheTwelfthInter-
nationalConferenceonLearningRepresentations
,2024.
Munkhdalai,T.,Faruqui,M.,andGopal,S.Leavenocon-
textbehind:Efcientinnitecontexttransformerswith
inni-attention,2024.URL
org/
abs/2404
07143
OpenAI.Deepresearch,2025a.URL
//openai
com/index/introducing-deep-
research/
.AI-poweredresearchassistanttool.
OpenAI.Codexcli:Alightweightcoding
agentforyourterminal,2025b.URL
//developers
openai
com/codex/cli/
OpenAI,Jaech,A.,Kalai,A.,Lerer,A.,Richardson,A.,
El-Kishky,A.,Low,A.,Helyar,A.,Madry,A.,Beu-
tel,A.,Carney,A.,Iftimie,A.,Karpenko,A.,Passos,
A.T.,Neitz,A.,Prokoev,A.,Wei,A.,Tam,A.,Bennett,
A.,Kumar,A.,Saraiva,A.,Vallone,A.,Duberstein,A.,
Kondrich,A.,Mishchenko,A.,Applebaum,A.,Jiang,A.,
Nair,A.,Zoph,B.,Ghorbani,B.,Rossen,B.,Sokolowsky,
B.,Barak,B.,McGrew,B.,Minaiev,B.,Hao,B.,Baker,
B.,Houghton,B.,McKinzie,B.,Eastman,B.,Lugaresi,
C.,Bassin,C.,Hudson,C.,Li,C.M.,deBourcy,C.,Voss,
C.,Shen,C.,Zhang,C.,Koch,C.,Orsinger,C.,Hesse,
C.,Fischer,C.,Chan,C.,Roberts,D.,Kappler,D.,Levy,
D.,Selsam,D.,Dohan,D.,Farhi,D.,Mely,D.,Robinson,
D.,Tsipras,D.,Li,D.,Oprica,D.,Freeman,E.,Zhang,
E.,Wong,E.,Proehl,E.,Cheung,E.,Mitchell,E.,Wal-
lace,E.,Ritter,E.,Mays,E.,Wang,F.,Such,F.P.,Raso,
F.,Leoni,F.,Tsimpourlas,F.,Song,F.,vonLohmann,
F.,Sulit,F.,Salmon,G.,Parascandolo,G.,Chabot,G.,
Zhao,G.,Brockman,G.,Leclerc,G.,Salman,H.,Bao,
H.,Sheng,H.,Andrin,H.,Bagherinezhad,H.,Ren,H.,
Lightman,H.,Chung,H.W.,Kivlichan,I.,O'Connell,
I.,Osband,I.,Gilaberte,I.C.,Akkaya,I.,Kostrikov,I.,
Sutskever,I.,Kofman,I.,Pachocki,J.,Lennon,J.,Wei,
J.,Harb,J.,Twore,J.,Feng,J.,Yu,J.,Weng,J.,Tang,J.,
Yu,J.,Candela,J.Q.,Palermo,J.,Parish,J.,Heidecke,
J.,Hallman,J.,Rizzo,J.,Gordon,J.,Uesato,J.,Ward,
J.,Huizinga,J.,Wang,J.,Chen,K.,Xiao,K.,Singhal,
K.,Nguyen,K.,Cobbe,K.,Shi,K.,Wood,K.,Rimbach,
K.,Gu-Lemberg,K.,Liu,K.,Lu,K.,Stone,K.,Yu,K.,
Ahmad,L.,Yang,L.,Liu,L.,Maksin,L.,Ho,L.,Fedus,
L.,Weng,L.,Li,L.,McCallum,L.,Held,L.,Kuhn,L.,
Kondraciuk,L.,Kaiser,L.,Metz,L.,Boyd,M.,Trebacz,
M.,Joglekar,M.,Chen,M.,Tintor,M.,Meyer,M.,Jones,
M.,Kaufer,M.,Schwarzer,M.,Shah,M.,Yatbaz,M.,
Guan,M.Y.,Xu,M.,Yan,M.,Glaese,M.,Chen,M.,
Lampe,M.,Malek,M.,Wang,M.,Fradin,M.,McClay,
M.,Pavlov,M.,Wang,M.,Wang,M.,Murati,M.,Bavar-
ian,M.,Rohaninejad,M.,McAleese,N.,Chowdhury,
N.,Chowdhury,N.,Ryder,N.,Tezak,N.,Brown,N.,
Nachum,O.,Boiko,O.,Murk,O.,Watkins,O.,Chao,P.,
Ashbourne,P.,Izmailov,P.,Zhokhov,P.,Dias,R.,Arora,
R.,Lin,R.,Lopes,R.G.,Gaon,R.,Miyara,R.,Leike,R.,
Hwang,R.,Garg,R.,Brown,R.,James,R.,Shu,R.,Cheu,
R.,Greene,R.,Jain,S.,Altman,S.,Toizer,S.,Toyer,S.,
Miserendino,S.,Agarwal,S.,Hernandez,S.,Baker,S.,
McKinney,S.,Yan,S.,Zhao,S.,Hu,S.,Santurkar,S.,
Chaudhuri,S.R.,Zhang,S.,Fu,S.,Papay,S.,Lin,S.,Bal-
aji,S.,Sanjeev,S.,Sidor,S.,Broda,T.,Clark,A.,Wang,
T.,Gordon,T.,Sanders,T.,Patwardhan,T.,Sottiaux,T.,
Degry,T.,Dimson,T.,Zheng,T.,Garipov,T.,Stasi,T.,
Bansal,T.,Creech,T.,Peterson,T.,Eloundou,T.,Qi,V.,
Kosaraju,V.,Monaco,V.,Pong,V.,Fomenko,V.,Zheng,
W.,Zhou,W.,McCabe,W.,Zaremba,W.,Dubois,Y.,Lu,
Y.,Chen,Y.,Cha,Y.,Bai,Y.,He,Y.,Zhang,Y.,Wang,Y.,
Shao,Z.,andLi,Z.Openaio1systemcard,2024.URL
16720
Packer,C.,Wooders,S.,Lin,K.,Fang,V.,Patil,S.G.,
10
Stoica,I.,andGonzalez,J.E.Memgpt:Towardsllmsas
operatingsystems,2024.URL
abs/2310
08560
Press,O.,Smith,N.A.,andLewis,M.Trainshort,test
long:Attentionwithlinearbiasesenablesinputlengthex-
trapolation,2022.URL
2108
12409
QwenTeam.Qwen3-8b.
https://huggingface
co/
Qwen/Qwen3-8B
,2025a.
QwenTeam.Qwen3-coder-480b-a35b-instruct.
co/Qwen/Qwen3-
Coder-480B-A35B-Instruct
,2025b.
Redmon,J.andFarhadi,A.Yolov3:Anincrementalim-
provement,2018.URL
1804
02767
Robertson,S.andZaragoza,H.Theprobabilisticrele-
vanceframework:Bm25andbeyond.
Found.Trends
Inf.Retr.
,3(4):333389,April2009.ISSN1554-0669.
doi:10
1561/1500000019.URL
https://doi
1561/1500000019
Schroeder,P.,Morgan,N.,Luo,H.,andGlass,J.Thread:
Thinkingdeeperwithrecursivespawning,2025.URL
org/abs/2405
17402
SentientAI.Roma:Thebackboneforopen-
sourcemeta-agents,November2025.URL
https://blog
sentient
xyz/posts/
recursive-open-meta-agent
.Accessed:
2025-12-20.
Singh,A.,Fry,A.,Perelman,A.,Tart,A.,Ganesh,A.,
El-Kishky,A.,McLaughlin,A.,Low,A.,Ostrow,A.,
Ananthram,A.,Nathan,A.,Luo,A.,Helyar,A.,Madry,
A.,Efremov,A.,Spyra,A.,Baker-Whitcomb,A.,Beutel,
A.,Karpenko,A.,Makelov,A.,Neitz,A.,Wei,A.,Barr,
A.,Kirchmeyer,A.,Ivanov,A.,Christakis,A.,Gillespie,
A.,Tam,A.,Bennett,A.,Wan,A.,Huang,A.,Sandjideh,
A.M.,Yang,A.,Kumar,A.,Saraiva,A.,Vallone,A.,
Gheorghe,A.,Garcia,A.G.,Braunstein,A.,Liu,A.,
Schmidt,A.,Mereskin,A.,Mishchenko,A.,Applebaum,
A.,Rogerson,A.,Rajan,A.,Wei,A.,Kotha,A.,Srivas-
tava,A.,Agrawal,A.,Vijayvergiya,A.,Tyra,A.,Nair,
A.,Nayak,A.,Eggers,B.,Ji,B.,Hoover,B.,Chen,B.,
Chen,B.,Barak,B.,Minaiev,B.,Hao,B.,Baker,B.,
Lightcap,B.,McKinzie,B.,Wang,B.,Quinn,B.,Fioca,
B.,Hsu,B.,Yang,B.,Yu,B.,Zhang,B.,Brenner,B.,
Zetino,C.R.,Raymond,C.,Lugaresi,C.,Paz,C.,Hud-
son,C.,Whitney,C.,Li,C.,Chen,C.,Cole,C.,Voss,
C.,Ding,C.,Shen,C.,Huang,C.,Colby,C.,Hallacy,C.,
Koch,C.,Lu,C.,Kaplan,C.,Kim,C.,Minott-Henriques,
C.,Frey,C.,Yu,C.,Czarnecki,C.,Reid,C.,Wei,C.,
Decareaux,C.,Scheau,C.,Zhang,C.,Forbes,C.,Tang,
D.,Goldberg,D.,Roberts,D.,Palmie,D.,Kappler,D.,
Levine,D.,Wright,D.,Leo,D.,Lin,D.,Robinson,D.,
Grabb,D.,Chen,D.,Lim,D.,Salama,D.,Bhattacharjee,
D.,Tsipras,D.,Li,D.,Yu,D.,Strouse,D.,Williams,D.,
Hunn,D.,Bayes,E.,Arbus,E.,Akyurek,E.,Le,E.Y.,
Widmann,E.,Yani,E.,Proehl,E.,Sert,E.,Cheung,E.,
Schwartz,E.,Han,E.,Jiang,E.,Mitchell,E.,Sigler,E.,
Wallace,E.,Ritter,E.,Kavanaugh,E.,Mays,E.,Nikishin,
E.,Li,F.,Such,F.P.,deAvilaBelbutePeres,F.,Raso,
F.,Bekerman,F.,Tsimpourlas,F.,Chantzis,F.,Song,F.,
Zhang,F.,Raila,G.,McGrath,G.,Briggs,G.,Yang,G.,
Parascandolo,G.,Chabot,G.,Kim,G.,Zhao,G.,Valiant,
G.,Leclerc,G.,Salman,H.,Wang,H.,Sheng,H.,Jiang,
H.,Wang,H.,Jin,H.,Sikchi,H.,Schmidt,H.,Aspegren,
H.,Chen,H.,Qiu,H.,Lightman,H.,Covert,I.,Kivlichan,
I.,Silber,I.,Sohl,I.,Hammoud,I.,Clavera,I.,Lan,I.,
Akkaya,I.,Kostrikov,I.,Kofman,I.,Etinger,I.,Singal,
I.,Hehir,J.,Huh,J.,Pan,J.,Wilczynski,J.,Pachocki,J.,
Lee,J.,Quinn,J.,Kiros,J.,Kalra,J.,Samaroo,J.,Wang,
J.,Wolfe,J.,Chen,J.,Wang,J.,Harb,J.,Han,J.,Wang,
J.,Zhao,J.,Chen,J.,Yang,J.,Tworek,J.,Chand,J.,Lan-
don,J.,Liang,J.,Lin,J.,Liu,J.,Wang,J.,Tang,J.,Yin,
J.,Jang,J.,Morris,J.,Flynn,J.,Ferstad,J.,Heidecke,J.,
Fishbein,J.,Hallman,J.,Grant,J.,Chien,J.,Gordon,J.,
Park,J.,Liss,J.,Kraaijeveld,J.,Guay,J.,Mo,J.,Lawson,
J.,McGrath,J.,Vendrow,J.,Jiao,J.,Lee,J.,Steele,J.,
Wang,J.,Mao,J.,Chen,K.,Hayashi,K.,Xiao,K.,Salahi,
K.,Wu,K.,Sekhri,K.,Sharma,K.,Singhal,K.,Li,K.,
Nguyen,K.,Gu-Lemberg,K.,King,K.,Liu,K.,Stone,
K.,Yu,K.,Ying,K.,Georgiev,K.,Lim,K.,Tirumala,
K.,Miller,K.,Ahmad,L.,Lv,L.,Clare,L.,Fauconnet,
L.,Itow,L.,Yang,L.,Romaniuk,L.,Anise,L.,Byron,
L.,Pathak,L.,Maksin,L.,Lo,L.,Ho,L.,Jing,L.,Wu,
L.,Xiong,L.,Mamitsuka,L.,Yang,L.,McCallum,L.,
Held,L.,Bourgeois,L.,Engstrom,L.,Kuhn,L.,Feuvrier,
L.,Zhang,L.,Switzer,L.,Kondraciuk,L.,Kaiser,L.,
Joglekar,M.,Singh,M.,Shah,M.,Stratta,M.,Williams,
M.,Chen,M.,Sun,M.,Cayton,M.,Li,M.,Zhang,M.,
Aljubeh,M.,Nichols,M.,Haines,M.,Schwarzer,M.,
Gupta,M.,Shah,M.,Huang,M.,Dong,M.,Wang,M.,
Glaese,M.,Carroll,M.,Lampe,M.,Malek,M.,Shar-
man,M.,Zhang,M.,Wang,M.,Pokrass,M.,Florian,
M.,Pavlov,M.,Wang,M.,Chen,M.,Wang,M.,Feng,
M.,Bavarian,M.,Lin,M.,Abdool,M.,Rohaninejad,M.,
Soto,N.,Staudacher,N.,LaFontaine,N.,Marwell,N.,
Liu,N.,Preston,N.,Turley,N.,Ansman,N.,Blades,N.,
Pancha,N.,Mikhaylin,N.,Felix,N.,Handa,N.,Rai,N.,
Keskar,N.,Brown,N.,Nachum,O.,Boiko,O.,Murk,
O.,Watkins,O.,Gleeson,O.,Mishkin,P.,Lesiewicz,P.,
Baltescu,P.,Belov,P.,Zhokhov,P.,Pronin,P.,Guo,P.,
Thacker,P.,Liu,Q.,Yuan,Q.,Liu,Q.,Dias,R.,Puckett,
R.,Arora,R.,Mullapudi,R.T.,Gaon,R.,Miyara,R.,
Song,R.,Aggarwal,R.,Marsan,R.,Yemiru,R.,Xiong,
R.,Kshirsagar,R.,Nuttall,R.,Tsiupa,R.,Eldan,R.,
Wang,R.,James,R.,Ziv,R.,Shu,R.,Nigmatullin,R.,
Jain,S.,Talaie,S.,Altman,S.,Arnesen,S.,Toizer,S.,
Toyer,S.,Miserendino,S.,Agarwal,S.,Yoo,S.,Heon,S.,
Ethersmith,S.,Grove,S.,Taylor,S.,Bubeck,S.,Banesiu,
S.,Amdo,S.,Zhao,S.,Wu,S.,Santurkar,S.,Zhao,S.,
Chaudhuri,S.R.,Krishnaswamy,S.,Shuaiqi,Xia,Cheng,
S.,Anadkat,S.,Fishman,S.P.,Tobin,S.,Fu,S.,Jain,
S.,Mei,S.,Egoian,S.,Kim,S.,Golden,S.,Mah,S.,
Lin,S.,Imm,S.,Sharpe,S.,Yadlowsky,S.,Choudhry,
S.,Eum,S.,Sanjeev,S.,Khan,T.,Stramer,T.,Wang,
T.,Xin,T.,Gogineni,T.,Christianson,T.,Sanders,T.,
Patwardhan,T.,Degry,T.,Shadwell,T.,Fu,T.,Gao,T.,
Garipov,T.,Sriskandarajah,T.,Sherbakov,T.,Kaftan,
T.,Hiratsuka,T.,Wang,T.,Song,T.,Zhao,T.,Peter-
son,T.,Kharitonov,V.,Chernova,V.,Kosaraju,V.,Kuo,
V.,Pong,V.,Verma,V.,Petrov,V.,Jiang,W.,Zhang,
W.,Zhou,W.,Xie,W.,Zhan,W.,McCabe,W.,DePue,
W.,Ellsworth,W.,Bain,W.,Thompson,W.,Chen,X.,
Qi,X.,Xiang,X.,Shi,X.,Dubois,Y.,Yu,Y.,Khakbaz,
Y.,Wu,Y.,Qian,Y.,Lee,Y.T.,Chen,Y.,Zhang,Y.,
Xiong,Y.,Tian,Y.,Cha,Y.,Bai,Y.,Yang,Y.,Yuan,
Y.,Li,Y.,Zhang,Y.,Yang,Y.,Jin,Y.,Jiang,Y.,Wang,
Y.,Wang,Y.,Liu,Y.,Stubenvoll,Z.,Dou,Z.,Wu,Z.,
andWang,Z.Openaigpt-5systemcard,2025.URL
03267
Smith,C.Openhandscontextcondensensa-
tionformoreefcientaiagents,2025.URL
https://openhands
dev/blog/openhands-
context-condensensation-for-more-
efficient-ai-agents
Sun,W.,Lu,M.,Ling,Z.,Liu,K.,Yao,X.,Yang,Y.,and
Chen,J.Scalinglong-horizonllmagentviacontext-
folding,2025.URL
2510
11967
Surs,D.,Menon,S.,andVondrick,C.Vipergpt:Visualin-
ferenceviapythonexecutionforreasoning.
Proceedings
ofIEEEInternationalConferenceonComputerVision
(ICCV)
,2023.
Wang,X.,Chen,Y.,Yuan,L.,Zhang,Y.,Li,Y.,Peng,
H.,andJi,H.Executablecodeactionselicitbetter
llmagents,2024.URL
01030
Wu,J.,Ouyang,L.,Ziegler,D.M.,Stiennon,N.,Lowe,R.,
Leike,J.,andChristiano,P.Recursivelysummarizing
bookswithhumanfeedback,2021.URL
org/abs/2109
10862
Wu,X.,Li,K.,Zhao,Y.,Zhang,L.,Ou,L.,Yin,H.,Zhang,
Z.,Yu,X.,Zhang,D.,Jiang,Y.,Xie,P.,Huang,F.,Cheng,
M.,Wang,S.,Cheng,H.,andZhou,J.Resum:Un-
lockinglong-horizonsearchintelligenceviacontextsum-
marization,2025.URL
2509
13313
Yang,A.,Li,A.,Yang,B.,Zhang,B.,Hui,B.,Zheng,
B.,Yu,B.,Gao,C.,Huang,C.,Lv,C.,Zheng,C.,Liu,
D.,Zhou,F.,Huang,F.,Hu,F.,Ge,H.,Wei,H.,Lin,
H.,Tang,J.,Yang,J.,Tu,J.,Zhang,J.,Yang,J.,Yang,
J.,Zhou,J.,Zhou,J.,Lin,J.,Dang,K.,Bao,K.,Yang,
K.,Yu,L.,Deng,L.,Li,M.,Xue,M.,Li,M.,Zhang,
P.,Wang,P.,Zhu,Q.,Men,R.,Gao,R.,Liu,S.,Luo,
S.,Li,T.,Tang,T.,Yin,W.,Ren,X.,Wang,X.,Zhang,
X.,Ren,X.,Fan,Y.,Su,Y.,Zhang,Y.,Zhang,Y.,Wan,
Y.,Liu,Y.,Wang,Z.,Cui,Z.,Zhang,Z.,Zhou,Z.,and
Qiu,Z.Qwen3technicalreport,2025.URL
org/abs/2505
09388
Yao,S.,Zhao,J.,Yu,D.,Du,N.,Shafran,I.,Narasimhan,
K.,andCao,Y.React:Synergizingreasoningand
actinginlanguagemodels,2023.URL
org/abs/2210
03629
Ye,R.,Zhang,Z.,Li,K.,Yin,H.,Tao,Z.,Zhao,Y.,Su,L.,
Zhang,L.,Qiao,Z.,Wang,X.,Xie,P.,Huang,F.,Chen,
S.,Zhou,J.,andJiang,Y.Agentfold:Long-horizonweb
agentswithproactivecontextmanagement,2025.URL
org/abs/2510
24699
Yu,H.,Chen,T.,Feng,J.,Chen,J.,Dai,W.,Yu,Q.,
Zhang,Y.-Q.,Ma,W.-Y.,Liu,J.,Wang,M.,andZhou,
H.Memagent:Reshapinglong-contextllmwithmulti-
convrl-basedmemoryagent,2025.URL
org/abs/2507
02259
Zelikman,E.,Wu,Y.,Mu,J.,andGoodman,N.D.Star:
Bootstrappingreasoningwithreasoning,2022.URL
org/abs/2203
14465
Zelikman,E.,Harik,G.,Shao,Y.,Jayasiri,V.,Haber,N.,
andGoodman,N.D.Quiet-star:Languagemodelscan
teachthemselvestothinkbeforespeaking,2024.URL
org/abs/2403
09629
Zhang,G.,Fu,M.,Wan,G.,Yu,M.,Wang,K.,andYan,
S.G-memory:Tracinghierarchicalmemoryformulti-
agentsystems,2025.URL
abs/2506
07398
Zhu,A.,Dugan,L.,andCallison-Burch,C.Redel:Atoolkit
forllm-poweredrecursivemulti-agentsystems,2024.
org/abs/2408
02248
12
A.AdditionalTrainingDetails
Wetrained
asaverysmallscaleexerciseintrainingtherstnativelyrecursivelanguagemodel.We
hypothesizedthat,thoughactingasanRLMappearstoproducesophisticatedbehaviorduetorecursion,itcanbesufcient
tofocusonimprovingtherootLM'sabilitytointeractwiththeprogrammaticrepresentationofthepromptintheREPLand
todiscernwhensub-callsareuseful.Inotherwords,whileatypicalRLMtrajectorycanbeextremelylongduetoallofthe
sub-callspotentiallylaunched(possibly
foraprompt
),theleafsub-callsareessentiallygeneral-purposeLLM
requestsandthemajorhurdleislearningtooperateastherootmodel.
Thissimpleinsightallowedustoexploreasimilarlysimplerecipefortraining.Inparticular,wesampledRLMtrajectories
fromalargerlanguagemodel(Qwen3-Coder-480B-A35B-Instruct;
)and,afterltering,distilledthemtoa
smallermodel(Qwen3-8B;
)fromthesamemodelfamily.WeevaluatedRLM(Qwen3-Coder-480B-A35B)
on750EnglishLongBenchPro(
)tasks,collectingatotalof2250candidatetrajectories.
Werstremovetrajectoriesthatscoreexactly0.0onthebenchmarkordonotgobeyondoneturn,bringingitdownto1,072
candidatetrajectories.WeseparatedeachrootRLMturn(i.e.iteration)asaseparateSFTsampleconsistingofaninput(the
fullhistory)andoutput(theoutputtherootLMgaveatthatstep).
WethenappliedalteringsteptoremoveturnsbeyondthecontextlimitofQwen3-8B(weapproximatedthisas100k
characters),andalsoappliedanextraprogrammaticcorrectionsteptoxsmalltemplatemistakesinRLMusage(e.g.
outputtingnalanswers,callingtheREPL,etc.).Toelaborate,wenoticedthattrajectoriesgeneratedbyQwen3-Coder-
480B-A35BhadnoticeablemistakesinfollowingtheRLMinstructions,whichhurttheperformanceofthedistilled
RLM-Qwen3-8B.Forexample,itwouldoftenmixFINAL(answer)withFINAL(variableinREPL).Weaddedanextra
programmaticxingsteptolookforcommontemplatedmistakesandpatchthem,leadingtomuchbetterperformanceinthe
nal
.Intotal,16%ofturnscleanedincorrectlyusedFINALanswers,and13%ofturnsincorrectlycalled
avariablefromtheREPL(i.e.FINAL_VAR)asanalanswer.InFigure
,weshowpre-andpost-lteringstatisticsforour
trainingtrajectories.
Figure5.
WeplotstatisticsfortheRLMtrajectoriesonLongBenchProthatwerecollectedandlteredtotrain
.Theleft
plotsshowtheunlteredtrajectories,andrightplotsshowthepost-lteringtrajectories.
Weusedthe
prime-rl
library(
Intellect
)forne-tuning.Weusedabatchsizeof64for300trainingsteps,training
for48H100hours.Whilethisexceedinglysimpletrainingrecipewasabletodemonstratesubstantialgainsforour8B
model,wecallonfutureworktoinvestigatetrainingnativeRLMsmuchmorethoroughly.Weexpectthatdoingsoatmuch
largerscalesintermsofmodelsize,numberandvarietyofexamples,andnumberof(ideallyon-policyandonline)rollouts
willbenecessarytomaximizethepotentialofRLMs.
B.NegativeResults:ThingsweTriedthatDidNotWork.
Drawinginspirationfrom
Redmon&Farhadi
2018
),wetrytobedescriptiveaboutwhattricks,quirks,andotherrelevant
thingsfailedandsucceededinaconcisemanner.Someobservationsarebasedonlongersupplementaryexperiments,while
othersarebasedonsmallsamplesofresults.
UsingtheexactsameRLMsystempromptacrossallmodelscanbeproblematic.
WeoriginallywrotetheRLMsystem
promptwithincontextexamplesforGPT-5,andtriedtousethesamesystempromptforQwen3-Coder,butfoundthat
itledtodifferent,undesirablebehaviorinthetrajectory.WehadtoaddasmallsentencetotheRLMsystempromptfor
Qwen3-Codertopreventitfromusingtoomanyrecursivesub-calls.
ModelswithoutsufcientcodingcapabilitiesstruggleasRLMs.
OurinstantiationofRLMsreliesontheabilitytoreason
throughanddealwiththecontextinaREPLenvironment.Wefoundfromsmallscaleexperimentsthatsmallermodelslike
Qwen3-8B(
)struggledwithoutsufcientcodingabilities.
ThinkingmodelswithoutsufcientoutputtokensstruggleasRLMs.
Inadditionto
Qwen3-Coder-480B-A35B-Instruct
,wealsotriedexperimentingwith
Qwen3-235B-A22B
astheRLM.
Whilewefoundpositiveresultsacrosstheboardfromthebasemodel(e.g.onOOLONG(
),performance
jumpedfrom
30%
38%
),thesmallergapcomparedtotheevaluatedmodelsinthemainexperiments(Table
)aredueto
multipletrajectoriesrunningoutofoutputtokenswhileproducingoutputsduetothinkingtokensexceedingthemaximum
outputtokenlengthofanindividualLMcall.
RLMswithoutasynchronousLMcallsareslow.
Weimplementedallsub-LMqueriesnaivelyasblocking/sequential
calls,whichcausedourRLMexperimentstobeslow,especiallycomparedtojustthebasemodel.Wearecondentthatthis
canberesolvedwitharobustimplementation.
Dependingonthemodel,distinguishingbetweenanalanswerandathoughtisbrittleforRLMs.
Thecurrent
strategyfordistinguishingbetweenanextturn"andanalanswerfortheRLMistohaveitwrapitsanswerinFINAL()
orFINAL_VAR()tags.Similartointuitionaboutstructuredoutputsdegradingperformance,wealsofoundthemodelto
makestrangedecisions(e.g.itoutputsitsplanasanalanswer).Weaddedminorsafeguards,butwealsobelievethisissue
shouldbeavoidedaltogetherinthefuturewhenmodelsaretrainedasRLMs.
C.AdditionalMethodsandBaselineDetails
C.1.PromptsforExperiments
Wefocusonmethodsthatareentirelytaskagnostic,sowexourpromptforeachmethodacrossalltasks.FortheRLM
prompt,theonlydifferencebetweenGPT-5andQwen3-CoderisanaddedlineinthebeginningthatwarnsQwen3-Coder
nottousetoomanysub-LMcallswefoundinpracticethatwithoutthiswarning,themodelwilltrytoperformasubcall
oneverything,leadingtothousandsofLMsubcallsforbasictasks!Forthene-tunedQwen3-8Bexperiment,weprovidea
slightlydifferentpromptduetothedifferencesincontextwindowsizeofthesmallermodel(from272kto32k).Inthis
section,weprovidethesystempromptusedforallmethodsin
3.1
(otherthanthebasemodel,whichdoesnotincludea
systemprompt).
(1a)Thesystempromptfor
forGPT-5:
Youaretaskedwithansweringaquerywithassociatedcontext.Youcanaccess,transform,andanalyzethiscontextinteractively
inaREPLenvironmentthatcanrecursivelyquerysub-LLMs,whichyouarestronglyencouragedtouseasmuchaspossible.You
willbequeriediterativelyuntilyouprovideafinalanswer.
Yourcontextisa{context_type}with{context_total_length}totalcharacters,andisbrokenupintochunksofcharlengths:{
context_lengths}.
TheREPLenvironmentisinitializedwith:
1.A`context`variablethatcontainsextremelyimportantinformationaboutyourquery.Youshouldcheckthecontentofthe`
context`variabletounderstandwhatyouareworkingwith.Makesureyoulookthroughitsufficientlyasyouansweryour
query.
2.A`llm_query`functionthatallowsyoutoqueryanLLM(thatcanhandlearound500Kchars)insideyourREPLenvironment.
3.Theabilitytouse`print()`statementstoviewtheoutputofyourREPLcodeandcontinueyourreasoning.
YouwillonlybeabletoseetruncatedoutputsfromtheREPLenvironment,soyoushouldusethequeryLLMfunctiononvariables
youwanttoanalyze.Youwillfindthisfunctionespeciallyusefulwhenyouhavetoanalyzethesemanticsofthecontext.
Usethesevariablesasbufferstobuildupyourfinalanswer.
MakesuretoexplicitlylookthroughtheentirecontextinREPLbeforeansweringyourquery.Anexamplestrategyistofirstlook
atthecontextandfigureoutachunkingstrategy,thenbreakupthecontextintosmartchunks,andqueryanLLMperchunk
withaparticularquestionandsavetheanswerstoabuffer,thenqueryanLLMwithallthebufferstoproduceyourfinal
answer.
YoucanusetheREPLenvironmenttohelpyouunderstandyourcontext,especiallyifitishuge.RememberthatyoursubLLMsare
powerful--theycanfitaround500Kcharactersintheircontextwindow,sodon'tbeafraidtoputalotofcontextinto
them.Forexample,aviablestrategyistofeed10documentspersub-LLMquery.Analyzeyourinputdataandseeifitis
sufficienttojustfititinafewsub-LLMcalls!
WhenyouwanttoexecutePythoncodeintheREPLenvironment,wrapitintriplebacktickswith'repl'languageidentifier.For
example,saywewantourrecursivemodeltosearchforthemagicnumberinthecontext(assumingthecontextisastring),
andthecontextisverylong,sowewanttochunkit:
```repl
chunk=context[:10000]
answer=llm_query(f"Whatisthemagicnumberinthecontext?Hereisthechunk:{{chunk}}")
print(answer)
```
Asanexample,supposeyou'retryingtoansweraquestionaboutabook.Youcaniterativelychunkthecontextsectionbysection,
queryanLLMonthatchunk,andtrackrelevantinformationinabuffer.
query="InHarryPotterandtheSorcerer'sStone,didGryffindorwintheHouseCupbecausetheyled?"
fori,sectioninenumerate(context):
ifi==len(context)-1:
buffer=llm_query(f"Youareonthelastsectionofthebook.Sofaryouknowthat:{{buffers}}.Gatherfromthislast
sectiontoanswer{{query}}.Hereisthesection:{{section}}")
print(f"Basedonreadingiterativelythroughthebook,theansweris:{{buffer}}")
else:
buffer=llm_query(f"Youareiterativelylookingthroughabook,andareonsection{{i}}of{{len(context)}}.Gather
informationtohelpanswer{{query}}.Hereisthesection:{{section}}")
print(f"Aftersection{{i}}of{{len(context)}},youhavetracked:{{buffer}}")
Asanotherexample,whenthecontextisn'tthatlong(e.g.>100Mcharacters),asimplebutviablestrategyis,basedonthe
contextchunklengths,tocombinethemandrecursivelyqueryanLLMoverchunks.Forexample,ifthecontextisaList[str],
weaskthesamequeryovereachchunk:
query="Amanbecamefamousforhisbook"TheGreatGatsby".Howmanyjobsdidhehave?"
#Supposeourcontextis~1Mchars,andwewanteachsub-LLMquerytobe~0.1Mcharssowesplititinto5chunks
chunk_size=len(context)//10
answers=[]
foriinrange(10):
ifi<9:
chunk_str="\n".join(context[i
chunk_size:(i+1)
chunk_size])
chunk_size:])
answer=llm_query(f"Trytoanswerthefollowingquery:{{query}}.Herearethedocuments:\n{{chunk_str}}.Onlyanswerifyou
areconfidentinyouranswerbasedontheevidence.")
answers.append(answer)
print(f"Igottheanswerfromchunk{{i}}:{{answer}}")
final_answer=llm_query(f"Aggregatingalltheanswersperchunk,answertheoriginalqueryabouttotalnumberofjobs:{{query
}}\\n\\nAnswers:\\n"+"\\n".join(answers))
15
Asafinalexample,afteranalyzingthecontextandrealizingitsseparatedbyMarkdownheaders,wecanmaintainstatethrough
buffersbychunkingthecontextbyheaders,anditerativelyqueryinganLLMoverit:
#AfterfindingoutthecontextisseparatedbyMarkdownheaders,wecanchunk,summarize,andanswer
importre
sections=re.split(r'###(.+)',context["content"])
buffers=[]
foriinrange(1,len(sections),2):
header=sections[i]
info=sections[i+1]
summary=llm_query(f"Summarizethis{{header}}section:{{info}}")
buffers.append(f"{{header}}:{{summary}}")
final_answer=llm_query(f"Basedonthesesummaries,answertheoriginalquery:{{query}}\\n\\nSummaries:\\n"+"\\n".join(
buffers))
Inthenextstep,wecanreturnFINAL_VAR(final_answer).
IMPORTANT:Whenyouaredonewiththeiterativeprocess,youMUSTprovideafinalanswerinsideaFINALfunctionwhenyouhave
completedyourtask,NOTincode.Donotusethesetagsunlessyouhavecompletedyourtask.Youhavetwooptions:
1.UseFINAL(yourfinalanswerhere)toprovidetheanswerdirectly
2.UseFINAL_VAR(variable_name)toreturnavariableyouhavecreatedintheREPLenvironmentasyourfinaloutput
Thinkstepbystepcarefully,plan,andexecutethisplanimmediatelyinyourresponse--donotjustsay"Iwilldothis"or"I
willdothat".OutputtotheREPLenvironmentandrecursiveLLMsasmuchaspossible.Remembertoexplicitlyanswerthe
originalqueryinyourfinalanswer.
(1b)Thediffofthesystempromptfor
RLMwithREPL(Qwen3-Coder-480B-A35B)
,whichaddsalinefromtheprompt
aboveforGPT-5:
---a/REPL_SYSTEM_PROMPT_QWEN.txt
+++b/REPL_SYSTEM_PROMPT_QWEN.txt
@@-15,0+15,3@@
+IMPORTANT:Beverycarefulaboutusing`llm_query`asitincurshighruntimecosts.Alwaysbatchasmuchinformationas
reasonablypossibleintoeachcall(aimforaround~200kcharacterspercall).Forexample,ifyouhave1000linesof
informationtoprocess,it'smuchbettertosplitintochunksof5andcall`llm_query`oneachchunk(200callstotal)
ratherthanmaking1000individualcalls.Minimizethenumberof`llm_query`callsbybatchingrelatedinformationtogether.
(1c)Thediffofthesystempromptfor
RLMwithREPL(Qwen3-8B)
,whichhasafewchangesfromtheGPT-5prompt
duetodifferencesincontextlengthandsimilarsub-callingbehaviorasQwen3-Coder-480B-A35B:
---a/REPL_SYSTEM_PROMPT.txt
+++b/REPL_SYSTEM_PROMPT_QWEN3_8B.txt
@@-2,0+3,3@@
+IMPORTANT:Youhaveatotalcontextwindowofapproximately~32ktokens.Beverycarefulaboutcontextlengthlimits.Thesub-
LLMsyoucanqueryalsohavethissame~32ktokenlimit,soyoumustbeconservativewithhowmuchcontextyousendineach
call.
@@-7+10@@
-2.A`llm_query`functionthatallowsyoutoqueryanLLM(thatcanhandlearound500Kchars)insideyourREPLenvironment.
+2.A`llm_query`functionthatallowsyoutoqueryanLLM(thatcanhandlearound~100kchars,roughly32ktokens)insideyour
REPLenvironment.
@@-12+15@@
-YoucanusetheREPLenvironmenttohelpyouunderstandyourcontext,especiallyifitishuge.RememberthatyoursubLLMsare
+YoucanusetheREPLenvironmenttohelpyouunderstandyourcontext,especiallyifitishuge.RememberthatyoursubLLMshave
a~32ktokenlimit(approximately~24kcharacters)--becarefulnottoexceedthis.Forexample,aviablestrategyisto
feed2-3documentspersub-LLMquery.Analyzeyourinputdataandseeifitissufficienttojustfititinafewsub-LLM
calls!
reasonablypossibleintoeachcallwhilestayingwithinthe~32ktokenlimit(aimforaround~10k-15kcharacterspercallto
besafe).Forexample,ifyouhave1000linesofinformationtoprocess,it'smuchbettertosplitintochunksof50-100
andcall`llm_query`oneachchunk(10-20callstotal)ratherthanmaking1000individualcalls.Minimizethenumberof`
llm_query`callsbybatchingrelatedinformationtogether,butalwaysrespectthe~32ktokenlimit.
@@-15+20@@
-chunk=context[:10000]
+chunk=context[:1000]
@@-62,0+68@@
+FINAL_VAR(final_answer)
@@-66+73@@
-IMPORTANT:Whenyouaredonewiththeiterativeprocess,youMUSTprovideafinalanswerinsideaFINALfunctionwhenyouhave
+IMPORTANT:Whenyouaredonewiththeiterativeprocess,youMUSTprovideafinalanswerinsideaFINALfunctionwhenyouhave
completedyourtask,NOTincodeorrepltags.Donotusethesetagsunlessyouhavecompletedyourtask.Youhavetwo
options:
16
(2)Thesystempromptfor
RLMwithREPL(nosub-calls)
inaREPLenvironment,whichyouarestronglyencouragedtouseasmuchaspossible.Youwillbequeriediterativelyuntil
youprovideafinalanswer.
2.Theabilitytouse`print()`statementstoviewtheoutputofyourREPLcodeandcontinueyourreasoning.
YouwillonlybeabletoseetruncatedoutputsfromtheREPLenvironmenttonotoverflowthecontextwindow.Usethesevariables
asbufferstobuildupyourfinalanswer.
atthecontextandfigureoutachunkingstrategy,thenbreakupthecontextintosmartchunks,andsaveinformationto
buffers.
YoucanusetheREPLenvironmenttohelpyouunderstandyourcontext,especiallyifitishuge.
example,saywewanttopeekatthefirst10000charactersofthecontext:
print(f"First10000charactersofcontext:{{chunk}}")
Asanotherexample,afteranalyzingthecontextandrealizingweneedtosearchforspecifictopics,wecanuseregextofind
relevantsectionsandmaintainstatethroughbuffers:
#Afterfindingoutweneedtosearchfor"magic"and"number"inthecontext
query_terms=["magic","number"]
relevant_sections=[]
#Searchforsectionscontainingourqueryterms
fori,chunkinenumerate(context):
chunk_text=str(chunk).lower()
ifany(terminchunk_textforterminquery_terms):
relevant_sections.append((i,chunk))
#Processeachrelevantsectionandprintfindings
forsection_idx,section_contentinrelevant_sections:
print(f"Foundrelevantsection{{section_idx}}containingmagic/numberreferences:")
print(f"Content:{{section_content[:500]}}...")#Printfirst500chars
buffers.append(f"Section{{section_idx}}:Containsmagic/numberreferences")
print(f"Totalrelevantsectionsfound:{{len(relevant_sections)}}")
print("Summaryoffindings:")
forbufferinbuffers:
print(f"-{{buffer}}")
Note:Ifyouarereadytoprovideafinalanswer,youcannotwriteanythingotherthanthefinalanswerintheFINALorFINAL_VAR
tags.
willdothat".OutputtotheREPLenvironmentasmuchaspossible.Remembertoexplicitlyanswertheoriginalqueryinyour
finalanswer.
(3a)Thesystempromptfor
CodeActwithBM25
.WegiveCodeActaccesstoaBM25retrieverforBrowseComp+following
experimentsintheoriginalpaper(
).:
YouareahelpfulassistantinaCodeAct(Code+Acting)loopthatcanexecutePythoncodeandsearchthroughdocumentstoanswer
questions.
Youmustfollowthisformatforeachstep:
1.THINK:Reasonaboutwhatyouneedtodonext
2.ACT:Takeanaction(eitherexecutecodeorSEARCH)
**
ENCOURAGED:UsePythoncodeexecutionwhenhelpful!
-Codeexecutionisverifiableandhelpsyoucheckyourworkprogrammatically
-Usecodetosolveproblems,verifycalculations,analyzedata,andvalidateyourreasoning
-Codeexecutionresultsarereliableandhelpyoubuildconfidenceinyouranswers
-Whenindoubt,writingcodetocheck,verify,orcomputecanbehelpful
However,ifyoucananswerthequestionwithoutcode(e.g.,straightforwardfactualquestions,simplereasoning),youcan
provideyourfinalanswerdirectlywithoutexecutingcode
AvailableActions:
-ExecutePythoncode:Writecodein```pythoncodeblocks.Thecodewillbeexecutedandresultsreturned.
-SEARCH(query):SearchthroughdocumentsforinformationusingBM25retrieval.
-Providefinalanswer:Whenyouhaveenoughinformation,youcanprovideyourfinalansweras"ANSWER:[youranswer]"
FormatRequirements:
-Starteachturnwith"THINK:"followedbyyourreasoning
-Theneither:
WritePythoncodein```pythonblockstoexecute
Use"SEARCH(querytext)"tosearchdocuments
-Youcanexecutecodemultipletimes,searchmultipletimes,orcombineboth
-Codeexecutionresultswillbereturnedtoyouautomatically
-Variablespersistacrosscodeexecutionsinthesamesession
CRITICAL:Codeisexecutedas-isinafreshPythonenvironment.Youmustincludeallnecessaryimports,datadefinitions,and
contextwithinyourcodeblocks.Donotusefillers(e.g.FILLINWITHREALDATA),theyhavetobewrittenincode.
Exampleworkflow:
Question:Howmanywordsinthelist['error','correct','arrow','berry','carrot','mirror']haveexactly2r's?
THINK:Ineedtocounthowmanywordsinthelisthaveexactly2r's.IcanwritePythoncodeusingregextodothis.
```python
words=['error','correct','arrow','berry','carrot','mirror']
pattern=r'^[^r]
r[^r]
$'#Matcheswordswithexactly2r's
count=0
matching_words=[]
forwordinwords:
ifre.match(pattern,word):
count+=1
matching_words.append(word)
print(f"{word}has2r's")
print(f"Totalwordswith2r's:{count}")
[Codeexecutionresultsreturned...]
Examplewithsearch:
Question:Whatinformationisavailableaboutmachinelearninginthedocuments?
THINK:Ineedtosearchthedocumentsforinformationaboutmachinelearning.
SEARCH(machinelearning)
[Searchresultsreturned...]
---
Important:
-AlwaysstartwithTHINKtoreasonaboutyournextstep
-Youcancombinecodeexecutionandsearchasneeded
-Bestrategictoavoidexceedingthecontextwindow
CODEEXECUTION
:Usecodetoverify,check,andsolveproblemsprogrammaticallywhenhelpful.However,ifyoucananswerthe
questionwithoutcode(e.g.,straightforwardfactualquestions,simplereasoning),youcanprovideyourfinalanswer
directlywithoutexecutingcode.
CODEEXECUTIONCONTEXT
:Yourcodeisexecutedas-is.Youmustexplicitlyincludeallimports,data,andcontextneeded.
Variablespersistacrossexecutions,buteachcodeblockmustbeself-containedwithallnecessarysetup.
(3b)Thesystempromptfor
CodeAct
.FortasksotherthanBrowseComp+,aretrieverisnotusable/helpfulbecausethereis
nothingtoindexoritalltsincontext.Wemodifytheprompttoremovetheretriever.:
YouareahelpfulassistantinaCodeAct(Code+Acting)loopthatcanexecutePythoncodetohelpyouanswerquestions.
2.ACT:Takeanaction(executecode)
-ThenwritePythoncodein```pythonblockstoexecute
-Youcanexecutecodemultipletimes.
Answer:4
C.2.Summaryagentbaseline
Thesummarizationagentbaselinefollowsthescaffoldpresentedin
whichalsomimicshowcontextsaretypicallycompressedinamulti-turnsettinginagentslikeClaudeCode(
).Inaniterativefashion,theagentisgiveninputsuntilitscontextisfull,atwhichpointitisqueriedtosummarize
allrelevantinformationandcontinue.Iftheagentisgivenacontextinasinglestepthatislargerthanitsmodelcontext
window,itchunksupthiscontextandperformsthesummarizationprocessoverthesechunks.
ForourGPT-5baseline,wechosetouseGPT-5-nanotoperformsummarizationtoavoidexplodingcosts.Thisexplainsthe
largediscrepancyincostinTable
betweenGPT-5andQwen3-CoderonBrowseComp+,wherethesummaryagentusing
Qwen3-Coderisnearly
moreexpensiveonaverage.Onthistaskinparticular,wefoundonasmallersetof
random
samplesthattheperformancebetweenusingGPT-5andGPT-5-nanoiscomparable.
19
D.AdditionalBenchmarkDetails
WeprovideadditionaldetailsaboutthebenchmarksusedtoevaluateRLMsin
D.1.OOLONG-PairsBenchmark
TocreateOOLONG-Pairs,wesyntheticallygenerate
newtasksbasedontheground-truthlabelsfortheOOLONG(
Bertsch
splitforinputcontextsoflengthin[1024,2048,4096,8192,16384,32768,65536,131072,
262144,524288,1048576].SimilartoOOLONG,eachquestionrequirescorrectlypredicingthesemanticmappingforeach
entry.
EnsuringquadraticscalingonOOLONG-Pairs
.Wenoticedthatmanytasksthataggregateoverpairsofentriescould
actuallybesolvedwithoutlookingatthepairsandonlylookingateachentryinalinearfashion(e.g.usingtheprincipleof
inclusion-exclusioninsettheory),soweexplicitlycreatedquestionsthataskforallpairssatisfyingsomeproperties.
Task1
Intheabovedata,listallpairsofuserIDs(noduplicatepairs,listlowerIDrst)wherebothusershaveatleastoneinstance
withanumericvalueorlocation.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethe
labels,youneedtogureoutthelabelfromthesemanticsofthequestion):descriptionandabstractconcept,entity,human
being,numericvalue,location,abbreviation.Inyouranswer,listallpairsintheformat(user_id_1,user_id_2),separatedby
newlines.
Task2
withanentityorhumanbeing.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethe
Task3
withadescriptionandabstractconceptorabbreviation.Eachofthequestionscanbelabelledasoneofthelabels(thedata
doesnotprovidethelabels,youneedtogureoutthelabelfromthesemanticsofthequestion):descriptionandabstract
concept,entity,humanbeing,numericvalue,location,abbreviation.Inyouranswer,listallpairsintheformat(user_id_1,
user_id_2),separatedbynewlines.
Task4
withahumanbeingorlocation,andallinstancesthatareahumanbeingforbothusersmustbeafterJanuary6,2023.
Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethelabels,youneedtogureoutthe
labelfromthesemanticsofthequestion):descriptionandabstractconcept,entity,humanbeing,numericvalue,location,
abbreviation.Inyouranswer,listallpairsintheformat(user_id_1,user_id_2),separatedbynewlines.
Task5
withanentityornumericvalue,andallinstancesthatareanentityforbothusersmustbebeforeMarch15,2023.Eachof
thequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethelabels,youneedtogureoutthelabelfrom
thesemanticsofthequestion):descriptionandabstractconcept,entity,humanbeing,numericvalue,location,abbreviation.
Inyouranswer,listallpairsintheformat(user_id_1,user_id_2),separatedbynewlines.
Task6
withalocationorabbreviation.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethe
Task7
withadescriptionandabstractconceptornumericvalue,andallinstancesthatareanumericvalueforbothusersmust
beafterFebruary1,2023.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethelabels,
youneedtogureoutthelabelfromthesemanticsofthequestion):descriptionandabstractconcept,entity,humanbeing,
numericvalue,location,abbreviation.Inyouranswer,listallpairsintheformat(user_id_1,user_id_2),separatedby
Task8
withahumanbeingordescriptionandabstractconcept.Eachofthequestionscanbelabelledasoneofthelabels(thedata
Task9
withanentityorlocation,andallinstancesthatarealocationforbothusersmustbeafterApril10,2023.Eachofthe
questionscanbelabelledasoneofthelabels(thedatadoesnotprovidethelabels,youneedtogureoutthelabelfromthe
semanticsofthequestion):descriptionandabstractconcept,entity,humanbeing,numericvalue,location,abbreviation.In
youranswer,listallpairsintheformat(user_id_1,user_id_2),separatedbynewlines.
Task10
withanumericvalueorabbreviation,andallinstancesthatareanabbreviationforbothusersmustbebeforeMay20,2023.
Task11
Intheabovedata,listallpairsofuserIDs(noduplicatepairs,listlowerIDrst)suchthatoneuserhasatleastoneinstance
withentityandonewithabbreviation,andtheotheruserhasexactlyoneinstancewithentity.Eachofthequestionscanbe
labelledasoneofthelabels(thedatadoesnotprovidethelabels,youneedtogureoutthelabelfromthesemanticsofthe
question):descriptionandabstractconcept,entity,humanbeing,numericvalue,location,abbreviation.Inyouranswer,list
allpairsintheformat(user_id_1,user_id_2),separatedbynewlines.
Task12
Intheabovedata,listallpairsofuserIDs(noduplicatepairs,listlowerIDrst)suchthatoneuserhasatleasttwoinstances
withnumericvalue,andtheotheruserhasatleastoneinstancewithlocationandatleastoneinstancewithhumanbeing.
21
Task13
Intheabovedata,listallpairsofuserIDs(noduplicatepairs,listlowerIDrst)suchthatoneuserhasexactlyoneinstance
withdescriptionandabstractconcept,andtheotheruserhasatleastoneinstancewithabbreviationandatleastoneinstance
withentity.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethelabels,youneedto
gureoutthelabelfromthesemanticsofthequestion):descriptionandabstractconcept,entity,humanbeing,numeric
value,location,abbreviation.Inyouranswer,listallpairsintheformat(user_id_1,user_id_2),separatedbynewlines.
Task14
withhumanbeingandatleastoneinstancewithnumericvalue,andtheotheruserhasexactlytwoinstanceswithlocation.
Task15
withentity,atleastoneinstancewithlocation,andatleastoneinstancewithabbreviation,andtheotheruserhasexactly
oneinstancewithnumericvalue.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethe
Task16
withdescriptionandabstractconceptandatleastoneinstancewithhumanbeing,andtheotheruserhasatleasttwoinstances
withentityandexactlyoneinstancewithabbreviation.Eachofthequestionscanbelabelledasoneofthelabels(thedata
Task17
withnumericvalue,andtheotheruserhasatleastoneinstancewithlocationandatleastoneinstancewithdescriptionand
abstractconcept.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovidethelabels,youneedto
Task18
withabbreviationandexactlyoneinstancewithhumanbeing,andtheotheruserhasatleastoneinstancewithentityandat
leastoneinstancewithnumericvalue.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoesnotprovide
thelabels,youneedtogureoutthelabelfromthesemanticsofthequestion):descriptionandabstractconcept,entity,
humanbeing,numericvalue,location,abbreviation.Inyouranswer,listallpairsintheformat(user_id_1,user_id_2),
separatedbynewlines.
Task19
22
withlocationandatleastoneinstancewithentity,andtheotheruserhasexactlyoneinstancewithdescriptionandabstract
conceptandexactlyoneinstancewithabbreviation.Eachofthequestionscanbelabelledasoneofthelabels(thedatadoes
notprovidethelabels,youneedtogureoutthelabelfromthesemanticsofthequestion):descriptionandabstractconcept,
entity,humanbeing,numericvalue,location,abbreviation.Inyouranswer,listallpairsintheformat(user_id_1,user_id_2),
Task20
withnumericvalueandatleastoneinstancewithhumanbeing,andtheotheruserhasatleastoneinstancewithlocation,at
leastoneinstancewithentity,andexactlyoneinstancewithabbreviation.Eachofthequestionscanbelabelledasoneofthe
labels(thedatadoesnotprovidethelabels,youneedtogureoutthelabelfromthesemanticsofthequestion):description
andabstractconcept,entity,humanbeing,numericvalue,location,abbreviation.Inyouranswer,listallpairsintheformat
(user_id_1,user_id_2),separatedbynewlines.
D.2.ScalingHugeDocumentCorpusesinBrowseComp+
InadditiontotheBrowseComp+(
)resultsfor
=1000
documentsin
,wealsoincludeasmallersetof
resultsonasubsetof
tasksfromtheoriginal
150
toshowhowperformancedegradesasafunctionofinputsize.Inour
originalexperiments,thebaseLMswereunabletohandletheinputcontexts,soweaddresultstoshowhowtheydegrade.
Weincludetwonewbaselines,namely
ReActw/GPT-5+BM25
(avariantoftheCodeActbaselinewithoutaccesstoa
codeenvironment)and
GPT-5+pre-queryBM25
(GPT-5onpre-querieddocuments).
Figure6.
WeplottheperformanceandAPIcostperanswerofvariousmethodsusingGPT-5on20randomqueriesinBrowseComp-Plus
givenincreasingnumbersofdocumentsincontext.Onlytheiterativemethods(RLM,ReAct)maintainreasonableperformanceat100+
documents.
RLMsareabletoscalewellwithoutperformancedegradation.
RLM(GPT-5)istheonlymodel/agentabletoachieve
andmaintainperfectperformanceatthe1000documentscale,withtheablation(norecursion)abletosimilarlyachieve
90%
performance.ThebaseGPT-5modelapproaches,regardlessofhowtheyareconditioned,showclearsignsofperformance
dropoffasthenumberofdocumentsincrease.
RLMinferencecostscalesreasonably.
TheinferencecostofRLMsonthissetupscalelog-linearly,andarereasonably
boundedcomparedtoothercommonstrategieslikeReAct+BM25.IfweextrapolatetheoveralltokencostsofGPT-5
assumingithasaninnitecontextwindow,weobservethattheinferencecostofusingRLM(GPT-5)ischeaper.
E.AdditionalRLMTrajectories
Inthissection,weprovideseveralexampletrajectoriestohighlightcharacteristicsoffrontiermodelsasRLMs.Manyofthe
trajectoriesaretoolongtotintext,sowedescribeeachstepandshowspecicexampleswhenrelevant.
AfewnoticeablepropertiesofthesetrajectoriesarethatRLMsoftenmakenon-optimalchoicesdespitetheirstrongresults
.Forexample,inExample
E.2
,weobservedthattheRLMwithQwen3-Codercarefullyconstructsitsnalanswer
throughamixofrecursivesub-callsandcodeexecutionintherstiteration,butthendiscardsthisinformationandcontinues
wastingsub-callsbeforenotusingthesestoredanswers.Wealsoobserveddistinctdifferencesinmodelbehaviorsuchasin
Example
,wherewefoundQwen3-Codermakehundredstothousandsofrecursivesub-callsforasinglesimpletask,
whileGPT-5makesontheorderoften.Whiletheseexamplesarenotcomprehensive,theyprovideusefulqualitativeinsight
intohowtoimproveRLMs.
E.1.RLM(GPT-5)onBrowseComp-Plus-Query_74
Thetotalcostofthistrajectorywas
$0.079
.Inthistask,theagentmustndtheanswertothefollowingmulti-hopquery
givenacorpusof1000uniquedocuments(8.3Mtotaltokens)thatcontainevidencedocumentsandnegatives:
Thisvegetablestewusesfish,butaddingmeatispossible.Italsousesasaltyandintensecondiment,whichisthecritical
ingredientofthedish.Asof2023,atownshipholdsacelebrationnamedafterthisstew.Between1995and2005inclusive,
thisfestivitybeganafterauthoritiesshiftedthehighlightandsubjectoftheireventtosetthemapartfromotherareas
intheregionthatusethesameproductintheircelebrations.ThistownholdstheeventeveryyearafterFebruarybut
beforeSeptember.Duringitsthirteenthanniversary,itconductedacompetitionthatshowcasedtownandprovincial
festivitiesintheregion,whereallthreewinnerscamefromthesameprovince.Abeautypageantwasalsoapartofthe
celebration.Whatarethefirstandlastnamesofthepersonwhowonthatcontestthatyear?
Step1.
GPT-5(astherootLM)rstdecidestoprobeatthe1000documentlistwithregexqueries.Ithassomepriorsabout
theseevents(asshownfromitsparticularchoiceofwordsitlooksfor),butitalsolooksforspecickeywordsintheprompt
likebeautypagentandfestival.
Step2.
Afterrunningitsregexqueries,therootLMndsaninterestingsnippetonthechunkatindex6,soitlaunchesa
recursiveLMcalloverthissnippettolookforinformationrelevanttotheoriginalquery.TheRLMisabletobothstorethis
24
informationinavariable
answer6
,aswellasprintthisinformationoutfortherootLMtosee.Thesub-LMcallndsthe
answerislikely`MariaDalmacio`andstoresthisinformationbackintherootLM'senvironment.
Step3.
Aftercheckingtheinformationabove,therootLMreasonsthatithasenoughinformationtoanswerthequery.The
rootLMchoosestocheckitsansweragainwithtwoadditionalrecursiveLMcallstoconrmthatitsansweralignswiththis
check.Finally,therootLMreturnsitsnalansweras`MariaDalmacio`,whichisthecorrectanswer.
25
E.2.RLM(Qwen3-Coder)onOOLONG-Pairs-Query_3
$1.12
.Inthistask,theagentmustoutputallpairsofuserIDssatisfyingsomesetof
propertiesgivenalistofentries(32ktokenstotal).Thisisbothaninformationdenselonginputaswellaslongoutputtask,
makingitparticularlychallengingforcurrentLMs.
Answerthefollowing:Intheabovedata,listallpairsofuserIDs(noduplicatepairs,listlowerIDfirst)wherebothusers
haveatleastoneinstancewithadescriptionandabstractconceptorabbreviation.Eachofthequestionscanbelabelledas
oneofthelabels(thedatadoesnotprovidethelabels,youneedtofigureoutthelabelfromthesemanticsofthe
question):descriptionandabstractconcept,entity,humanbeing,numericvalue,location,abbreviation.Inyouranswer,
listallpairsintheformat(user_id_1,user_id_2),separatedbynewlines.YouranswermustbesortedbyfirstuserID.For
example,iftheansweristheInstanceIDpairs(22740,35839)and(35839,52032),youshouldreturn`(22740,35839),
(35839,52032)`.Ifthereisnoanswer,returnanemptylist[].
Themodelbeginsbyprobingthecontextwithvariouscodesnippets,includingprintingouttherstfewcharacters
andprintingouttherstfewlines.WenoticedinparticularthatQwen3-Coder-480B-A35Btendstooutputmultiplecode
blocksinasinglestepunlikeGPT-5,whichmakesoutputsinamoreiterativefashion.
Themodelcontinuesprobingbysplittingtheinputcontextbynewlinecharactersandcheckingroughlywhatthedataformat
lookslike.
26
Fromthegivenformat,themodelchoosestorstsemanticallyclassifythedatausingsub-LMcallsoversmallerchunks
oftheinput(toavoidcontextrotandmistakesinlargercontexts)andprovidesasamplebacktotherootLMofwhatit
observedduringthisprocess.
27
UsingtheseclassicationsoutputtedbyrecursiveLMcalls,themodelpassesthisvariableintoafunctiontocategorizeeach
programmatically.Fromhere,therootLMischoosingtoanswertherestofthequestionprogrammaticallyratherthanby
tryingtooutputallpairsthroughmodelgeneraetions.
TherootLMspecicallylooksforinstancessatisfyingthequery(theuserinthepairhastohaveatleastoneinstancewitha
descriptionandabstractionconceptorabbreviation)andaddsthemtoavariableoftargetusers.
29
TherootLMformsalistofuniquepairswiththisloop,andisessentiallynowabletoanswerthequestion.
Themodelhasstoredthesepairsinavariabletobeoutputtedattheend.Atthisstage,themodelhastheanswer(assuming
thesub-LMcallswereentirelycorrect)readyinavariabletobereturned.
Bythispointthemodelhasalreadysuccessfullyextractedtheanswer.Interestinglyhowever,asweobserved
frequentlywithQwen3-Coder,themodelwillcontinuetorepeatedlyverifyitsanswers.Themodelalsoattemptstoreturnits
answerwrappedina`FINAL_VAR()`tag,butitdoesnotacceptitsanswer.Thisislikelyaconsequenceofa)nottuningthe
promptspecicallyforthismodelandb)themodelnotbeingtrainedtoactasanRLM,butweincludethesedescriptionsin
30
textforbrevity.Atthisstep,themodelchecksitspairs.
ThemodelprintsouttherstandlastpairsandattemptstohavetherootLMverifyitscorrectness.
Step4.
Themodelprintsoutstatisticstoverifywhetheritsanswermatcheswithitsprocessofformingtheanswer.
Step5.
ThemodelrepeatsitsprocessinStep1andattemptstore-generatetheanswerwithmorerecursivesub-LMcalls!
Step6-11.
ThemodelrepeatsitsprocessinStep1withslightdifferenceandagainattemptstore-generatetheanswer
withmorerecursivesub-LMcalls!Itactuallyrepeatsthisprocess5times,beforenallyreturningananswerafterbeing
promptedtoprovideanalanswer.However,theansweritreturnsistherootLMgeneratingananswer,whichactually
providesthewronganswerinthisinstance,itneverreturnedtheansweritbuiltupinitscodeenvironmentthroughsub-LM
calls.ThisisanexampleofacasewheretheRLMfailed.
E.3.RLM(Qwen3-Coder)onOOLONG-Query_212
$0.38
.Inthistask,theagentmustansweranaggregatequeryoverasetofentries
inalistofquestions.Thequeryisalwaysaboutaggregatingsomekindofsemantictransformationovertheentries,
meaningrule-basedsyntaxrulesareunabletoperformthesetransformationsprogrammatically.Inthisexample,theRLMis
answeringthefollowingquestion:
Thefollowinglinescontainthousandsofgeneral-knowledgequestions,oneperline.EachlinehasaUserID,whichisnot
necessarilyunique,i.e.eachUserIDcanbeassociatedwithmultiplequestions.Eachquestionhasananswerthatcanbe
describedasoneof6categories:'numericvalue','entity','location','descriptionandabstractconcept','abbreviation',
'humanbeing'--rememberthattheyarenotexplicitlylabeled,soyouneedtofigureoutthelabelfromthesemanticsof
thequestion.Youwillbeaskedtoanswerquestionsabouttheaggregatelabelstatisticsacrossallexamplesinthisdataset
.Donottrytoguess,estimate,orapproximatetheresult.Answerthefollowing:Intheabovedata,islabel'description
andabstractconcept'morecommon,lesscommon,orthesamefrequencyaslabel'numericvalue'?Giveyourfinalanswerin
theform'Answer:descriptionandabstractconceptis[X]numericvalue',where[X]is'morecommonthan','lesscommonthan
',or'samefrequencyas'.
andprintingouttherstfewlines.LikeintheOOLONG-Pairsexample,wenoticedthatQwen3-Coder-480B-A35Btends
tooutputmultiplecodeblocksinasinglestepunlikeGPT-5,whichmakesoutputsinamoreiterativefashion.
Asmentionedpreviously,Qwen3-CoderdiffersfromGPT-5inhowliberalitisinitsuseofsub-calls.Thefunction
Qwen3-Coderdenesforclassifyingentriessemanticallyusesasub-LMcall
perline
,leadingtothousandsofrecursive
sub-callswhenappliedtothefullinputcontext.
31
Afterdeningandtestingseveralfunctionsforrunningtheaboveclassicationquestionoveritsinputcontext,the
rootLMlaunchesalongcodeexecutioncalltoclassifyandanswerthequery.
32
Final.
Themodelconcludesprogrammaticallyfromthelargenumberofsub-callsitperformedinStep2that`Answer:
descriptionandabstractconceptislesscommonthannumericvalue`wasthecorrectanswer.WhiletheRLMwasableto
concludethecorrectanswer,itlikelywouldhavebeenabletosolvethequestionwithsignicantlylesssub-calls.
E.4.RLM(GPT-5)onCodeQA-Query_44
$0.27
.Inthistask,theagentmustansweraquestionthatinvolvesunderstandingalarge
codebase.Thecodebasehereis900ktokens,andtheagentmustanswerthefollowingquery:
Youareahelpfulassistantthatcananswerquestionsaboutcoderepositories.Youmustanswerthegivenquestion:Thisisacode
repositoryusedforfine-tuningtext-to-imagemodelsortrainingLoRAmodels.Therepositoryisusedfortheauthor's
researchonsomerelateduses.BelowarethestepsIfollowedduringtheprocess.Couldyouhelpmecheckwhichoneisright
statement?basedonthestoredcontextanswerwithexactlyonenumberchoiceusingonlythechoicesprovided:
0:Inthisrepository,duringthetrainingprocess,tasksaredividedintomultipleprocessesbasedontheconfigurationfile,
suchas"extension,""extract,""generate,"andsoon.Foreachprocess,acorrespondingclasshasbeenwritten.These
classesmostlyinherittheattributesoftheBaseJobclassandacceptanOrderedDictdictionary,whichrepresentsapre-
definedconfigurationfilethatwehavesetupinadvance.Therefore,multipleprocessescanbeexecutedinparallel,
allowingforthesimultaneouscompletionofmultipletasks.Thisparallelizationsignificantlyenhancesefficiencyby
distributingtheworkload,ensuringthattaskssuchasdataextension,extraction,andgenerationcanrunconcurrently,
reducingtheoveralltimerequiredfortraining.
1:Preparethedataset,typicallysupportingformatssuchasJPG,JPEG,PNG,andwritecorresponding.txtfilestodescribethe
contentoftheimages.Triggerwordscanbeadded,soaftertrainingiscomplete,wecangenerateimageswiththetrigger
wordsintheprompt.Intheconfigdirectory,findtheconfigurationfilesandmodifythe.ymlfiles.Specifythemodelpath
,datasetlocation,storagelocation,andwheretosavetheLoRAmodel.Onlyafterconfiguringthesesettingscanitrun
properly.
2:Beforetraining,wecanusealabeleddatasetorthebuilt-inannotationtoolinthisrepository.Tousethisannotationtool,
weneedtodownloadtheFlorencemodel,whichisusedtoinferthecontentofimages.Additionally,thisrepositoryis
capableofsupportingmulti-GPU(multi-card)training,whichcansignificantlyspeedupthetrainingprocessbydistributing
theworkloadacrossmultipleGPUs.Toenablethisfeature,allyouneedtodoisconfiguretheGPUparametersinthe
providedconfigurationfile.ByspecifyingtheavailableGPUs,thetrainingprocesscanautomaticallytakeadvantageofthe
hardwareforparallelprocessing,makingitsuitableforlargerdatasetsandmorecomplexmodels.Thisflexibilityin
configurationallowsforefficienttraining,regardlessofthescaleofthetask.
3:Thisprojecthasseveralwaystorun.Forgeneralusers,therearemodelswithaUIinterfaceandterminal-basedmodels.
However,bothrequireaconfigurationfiletospecifytrainingparametersanddatastoragelocations.AfterLoRatrainingis
completed,wecanruntherun.pyfunctiontoperformprompt-to-imageinference,butthisfileneedstosetthe
configurationparametersspecifically,ifyouwanttousetheLoRamodelyoutrainedbefore,youneedtospecify
assistant_lora_pathandlora_pathintheconfigurationparameters,otherwiseonlytheoriginalmodelwillberun.(indexed
from0to3).
Itisnotalwaystruethataninputcontextcanbesolvedbypartitioningitandrecursivelysub-queryingmodelsover
eachpartition,butintasksthatarenotinformationdense,thisispossible.Inthiscase,themodelchoosestobreakdownthe
codebaseintopartsandsub-queryLMstolookforclues.Themodelthenaggregatesthesecluesandprovidesanalanswer
asaseparatesub-query.
TheRLManswerschoice`1',whichisthecorrectanswer.
F.AdditionalRuntimeandCostAnalysisofRLMs
WesupplementthecostandruntimeanalysisofRLMswithadditional,ne-grainedplots.InFigures
weincludea
histogramforthecostofeachmethodoneverytaskforbothGPT-5andQwen3-Coder.Wegenerallyobservelong-tailed,
high-variancetrajectoriesforRLMsinbothmodels.
Weadditionallyincludelog-scaledruntimeplotsforeachmethodbelow.Asweremarkedin
,theruntimeforthese
methodscanbesignicantlyimprovedthroughasynchronyofLMcallsandadditionalpromptingtodiscouragelongsub-LM
callsorcode.
ForthescalingplotinFigure
,wealsoprovidetheaverageAPIcostpertask.
34
Figure7.
PlottedquartilesoftheruntimeGPT-5acrossOOLONG,OOLONG-Pairs,CodeQA,andBrowseComp+(1K)forallmethods
describedin
.Weplotthe25th,50th,75th,and95thpercentiles.
Figure8.
PlottedquartilesoftheruntimeQwen3-Coder-480BacrossOOLONG,OOLONG-Pairs,CodeQA,andBrowseComp+(1K)for
allmethodsdescribedin
35
Figure9.
HistogramoftheAPIcostsforGPT-5acrossOOLONG,OOLONG-Pairs,CodeQA,andBrowseComp+(1K)forallmethods
36
Figure10.
HistogramoftheAPIcostsforQwen3-Coder-480BacrossOOLONG,OOLONG-Pairs,CodeQA,andBrowseComp+(1K)for
37
Figure11.
WeplottheAPIcostinUSDfortherunsinFigure
38